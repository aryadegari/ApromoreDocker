Creating network "apromoredocker_default" with the default driver
Pulling mysql (mysql:5.6.44)...
5.6.44: Pulling from library/mysql
0a4690c5d889: Pull complete
98aa2fc6cbeb: Pull complete
0777e6eb0e6f: Pull complete
2464189c041c: Pull complete
b45df9dc827d: Pull complete
8f57052b58bf: Pull complete
ee774b34419e: Pull complete
bcb6c29a9771: Pull complete
f5eace967cb6: Pull complete
fe457a2a894d: Pull complete
a3266082cf3b: Pull complete
Digest: sha256:02b3ddb41d6e5d48d24aa8e59e1cd5870ddaca8ba7cdedf6602f7e6266240d64
Status: Downloaded newer image for mysql:5.6.44
Pulling zookeeper (wurstmeister/zookeeper:3.4.6)...
3.4.6: Pulling from wurstmeister/zookeeper
a3ed95caeb02: Pull complete
ef38b711a50f: Pull complete
e057c74597c7: Pull complete
666c214f6385: Pull complete
c3d6a96f1ffc: Pull complete
3fe26a83e0ca: Pull complete
3d3a7dd3a3b1: Pull complete
f8cc938abe5f: Pull complete
9978b75f7a58: Pull complete
4d4dbcc8f8cc: Pull complete
ccf399e5f3b7: Pull complete
a80f54931267: Pull complete
551a52c71f3f: Pull complete
d77a729a2184: Pull complete
Digest: sha256:294d69bb580a614ed3128969b95b5355c480e84704d826cdf73e790b5a6e63fc
Status: Downloaded newer image for wurstmeister/zookeeper:3.4.6
Pulling kafka (wurstmeister/kafka:2.12-2.1.0)...
2.12-2.1.0: Pulling from wurstmeister/kafka
6c40cc604d8e: Pull complete
e78b80385239: Pull complete
f41fe1b6eee3: Pull complete
721a465103fa: Pull complete
fc5a499bfd17: Pull complete
2dbf197dc259: Pull complete
Digest: sha256:2d61489969d56bc9341097ab621283d6803b4cf0245d6af9a83191a0a2378074
Status: Downloaded newer image for wurstmeister/kafka:2.12-2.1.0
Building apromore
Step 1/24 : FROM openjdk:8
 ---> 03b20c1fa768
Step 2/24 : RUN groupadd -r apromore && useradd --no-log-init -r -g apromore apromore
 ---> Using cache
 ---> bfa1b73c4ea1
Step 3/24 : RUN apt-get -y update && apt-get -y install git && apt-get -y install python3 && apt-get -y install python3-pip && apt-get -y install xvfb && apt-get -y install python3-tk && apt-get -y clean
 ---> Using cache
 ---> 7143d88762d2
Step 4/24 : WORKDIR /opt/
 ---> Using cache
 ---> 8a5dd9196f2f
Step 5/24 : RUN mkdir /opt/apromore
 ---> Using cache
 ---> 491dcf83ba4d
Step 6/24 : COPY . /opt/apromore/
 ---> ba92eb3d2677
Step 7/24 : RUN chown -R apromore:apromore /opt/apromore && chmod -R 777 /opt/apromore
 ---> Running in 4634efdcbbec
Removing intermediate container 4634efdcbbec
 ---> 4cb8e5782722
Step 8/24 : RUN git clone https://github.com/nirdizati/nirdizati-training-backend.git
 ---> Running in fa4e26e1ff80
Cloning into 'nirdizati-training-backend'...
Removing intermediate container fa4e26e1ff80
 ---> b73f26c5f0a3
Step 9/24 : WORKDIR /opt/nirdizati-training-backend/
 ---> Running in b0a9a0e33e66
Removing intermediate container b0a9a0e33e66
 ---> 3f68e4bf9bb9
Step 10/24 : RUN pip3 install -r requirements.txt
 ---> Running in 152e863304ed
Collecting pandas>=0.21.0 (from -r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/a7/d9/e03b615e973c2733ff8fd53d95bd3633ecbfa81b5af2f83fe39647c02344/pandas-0.25.0-cp35-cp35m-manylinux1_x86_64.whl (10.3MB)
Collecting numpy>=1.13.0 (from -r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/bb/ef/d5a21cbc094d3f4d5b5336494dbcc9550b70c766a8345513c7c24ed18418/numpy-1.16.4-cp35-cp35m-manylinux1_x86_64.whl (17.2MB)
Collecting scikit_learn>=0.18.0 (from -r requirements.txt (line 3))
  Downloading https://files.pythonhosted.org/packages/99/6c/bbbf3452cd5c8ed8e6cb51d37e06ebea3113d347085a59a21f19ee76c8eb/scikit_learn-0.21.2-cp35-cp35m-manylinux1_x86_64.whl (6.6MB)
Collecting scipy>=1.0.0 (from -r requirements.txt (line 4))
  Downloading https://files.pythonhosted.org/packages/14/49/8f13fa215e10a7ab0731cc95b0e9bb66cf83c6a98260b154cfbd0b55fb19/scipy-1.3.0-cp35-cp35m-manylinux1_x86_64.whl (25.1MB)
Collecting xgboost>=0.7 (from -r requirements.txt (line 5))
  Downloading https://files.pythonhosted.org/packages/c1/24/5fe7237b2eca13ee0cfb100bec8c23f4e69ce9df852a64b0493d49dae4e0/xgboost-0.90-py2.py3-none-manylinux1_x86_64.whl (142.8MB)
Collecting kafka-python>=1.4 (from -r requirements.txt (line 6))
  Downloading https://files.pythonhosted.org/packages/82/39/aebe3ad518513bbb2260dd84ac21e5c30af860cc4c95b32acbd64b9d9d0d/kafka_python-1.4.6-py2.py3-none-any.whl (259kB)
Collecting pytz>=2017.2 (from pandas>=0.21.0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)
Collecting python-dateutil>=2.6.1 (from pandas>=0.21.0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)
Collecting joblib>=0.11 (from scikit_learn>=0.18.0->-r requirements.txt (line 3))
  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)
Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.6.1->pandas>=0.21.0->-r requirements.txt (line 1))
Installing collected packages: numpy, pytz, python-dateutil, pandas, joblib, scipy, scikit-learn, xgboost, kafka-python
Successfully installed joblib-0.13.2 kafka-python-1.4.6 numpy-1.16.4 pandas-0.25.0 python-dateutil-2.8.0 pytz-2019.1 scikit-learn-0.21.2 scipy-1.3.0 xgboost-0.90
Removing intermediate container 152e863304ed
 ---> 3923e5abdbd1
Step 11/24 : RUN chown -R apromore:apromore /opt/nirdizati-training-backend && chmod -R 777 /opt/nirdizati-training-backend
 ---> Running in f5131b9ec78f
Removing intermediate container f5131b9ec78f
 ---> 7b6b6c292839
Step 12/24 : ENV PYTHONPATH=/opt/nirdizati-training-backend/
 ---> Running in 4a248ce14817
Removing intermediate container 4a248ce14817
 ---> ac1ac780e827
Step 13/24 : WORKDIR /opt/
 ---> Running in b27454bd292f
Removing intermediate container b27454bd292f
 ---> 61a1da96d620
Step 14/24 : RUN git clone https://github.com/AdaptiveBProcess/SiMo-Discoverer.git && cd SiMo-Discoverer && git checkout 0527d1f25ae5079520deca6a61bcaf022ed8ecfd && cp /opt/apromore/simo-files/requirements.txt /opt/SiMo-Discoverer && mkdir /opt/SiMo-Discoverer/simo/ && cp /opt/apromore/simo-files/apromore-simo.py /opt/SiMo-Discoverer/simo/
 ---> Running in 415c88b40439
Cloning into 'SiMo-Discoverer'...
Note: checking out '0527d1f25ae5079520deca6a61bcaf022ed8ecfd'.

You are in 'detached HEAD' state. You can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by performing another checkout.

If you want to create a new branch to retain commits you create, you may
do so (now or later) by using -b with the checkout command again. Example:

  git checkout -b <new-branch-name>

HEAD is now at 0527d1f... Structural change in preamble of major changes
Removing intermediate container 415c88b40439
 ---> 2cd057965def
Step 15/24 : WORKDIR /opt/SiMo-Discoverer/
 ---> Running in 185d02da94d4
Removing intermediate container 185d02da94d4
 ---> d3243a2f1e44
Step 16/24 : RUN pip3 install -r requirements.txt
 ---> Running in 670b923fc044
Collecting lxml==4.2.5 (from -r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/eb/e2/02d18a1b3021b65409dd860f91cf0d68d79900f172bb3cc93cff21c3c951/lxml-4.2.5-cp35-cp35m-manylinux1_x86_64.whl (5.8MB)
Collecting matplotlib==2.2.3 (from -r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/de/af/6258db9b26313dd7ad70dba30a60bec62bf030a44208d4cb62966206666f/matplotlib-2.2.3-cp35-cp35m-manylinux1_x86_64.whl (12.6MB)
Collecting networkx==2.2 (from -r requirements.txt (line 3))
  Downloading https://files.pythonhosted.org/packages/f3/f4/7e20ef40b118478191cec0b58c3192f822cace858c19505c7670961b76b2/networkx-2.2.zip (1.7MB)
Collecting numpy==1.15.4 (from -r requirements.txt (line 4))
  Downloading https://files.pythonhosted.org/packages/86/04/bd774106ae0ae1ada68c67efe89f1a16b2aa373cc2db15d974002a9f136d/numpy-1.15.4-cp35-cp35m-manylinux1_x86_64.whl (13.8MB)
Collecting seaborn==0.9.0 (from -r requirements.txt (line 5))
  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)
Collecting statsmodels==0.9.0 (from -r requirements.txt (line 6))
  Downloading https://files.pythonhosted.org/packages/a5/75/758f980df4d971b909d2bc516d22494a2e871fe1f3968ff9798b52d20fb9/statsmodels-0.9.0-cp35-cp35m-manylinux1_x86_64.whl (7.3MB)
Collecting cycler>=0.10 (from matplotlib==2.2.3->-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl
Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib==2.2.3->-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/9f/dc/b205465a60baca8e04a1555a84d9c79f910661765056f071fb6fc2db4841/pyparsing-2.4.1-py2.py3-none-any.whl (65kB)
Collecting kiwisolver>=1.0.1 (from matplotlib==2.2.3->-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/ee/18/4cd2e84c6aff0c6a50479118083d20b9e676e5175a913c0ea76d700fc244/kiwisolver-1.1.0-cp35-cp35m-manylinux1_x86_64.whl (90kB)
Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib==2.2.3->-r requirements.txt (line 2))
Requirement already satisfied: pytz in /usr/local/lib/python3.5/dist-packages (from matplotlib==2.2.3->-r requirements.txt (line 2))
Requirement already satisfied: six>=1.10 in /usr/lib/python3/dist-packages (from matplotlib==2.2.3->-r requirements.txt (line 2))
Collecting decorator>=4.3.0 (from networkx==2.2->-r requirements.txt (line 3))
  Downloading https://files.pythonhosted.org/packages/5f/88/0075e461560a1e750a0dcbf77f1d9de775028c37a19a346a6c565a257399/decorator-4.4.0-py2.py3-none-any.whl
Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.5/dist-packages (from seaborn==0.9.0->-r requirements.txt (line 5))
Requirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.5/dist-packages (from seaborn==0.9.0->-r requirements.txt (line 5))
Collecting patsy (from statsmodels==0.9.0->-r requirements.txt (line 6))
  Downloading https://files.pythonhosted.org/packages/ea/0c/5f61f1a3d4385d6bf83b83ea495068857ff8dfb89e74824c6e9eb63286d8/patsy-0.5.1-py2.py3-none-any.whl (231kB)
Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from kiwisolver>=1.0.1->matplotlib==2.2.3->-r requirements.txt (line 2))
Building wheels for collected packages: networkx
  Running setup.py bdist_wheel for networkx: started
  Running setup.py bdist_wheel for networkx: finished with status 'done'
  Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91
Successfully built networkx
Installing collected packages: lxml, cycler, pyparsing, numpy, kiwisolver, matplotlib, decorator, networkx, seaborn, patsy, statsmodels
  Found existing installation: numpy 1.16.4
    Uninstalling numpy-1.16.4:
      Successfully uninstalled numpy-1.16.4
Successfully installed cycler-0.10.0 decorator-4.4.0 kiwisolver-1.1.0 lxml-4.2.5 matplotlib-2.2.3 networkx-2.2 numpy-1.15.4 patsy-0.5.1 pyparsing-2.4.1 seaborn-0.9.0 statsmodels-0.9.0
Removing intermediate container 670b923fc044
 ---> 7bdbe49526c4
Step 17/24 : RUN chown -R apromore:apromore /opt/SiMo-Discoverer && chmod -R 777 /opt/SiMo-Discoverer/
 ---> Running in bc90c0ccb7b9
Removing intermediate container bc90c0ccb7b9
 ---> 663049bda632
Step 18/24 : ENV PYTHONPATH=/opt/SiMo-Discoverer/
 ---> Running in c9861bc7419c
Removing intermediate container c9861bc7419c
 ---> 70f8ecafe524
Step 19/24 : RUN cp /opt/apromore/virgo-tomcat-server-3.6.4.RELEASE/liblpsolve55/* /usr/local/lib     && ldconfig     && chmod 755 /usr/local/lib/liblpsolve55j.so
 ---> Running in 41c1a07f0a94
Removing intermediate container 41c1a07f0a94
 ---> d983f0885506
Step 20/24 : ENV LD_LIBRARY_PATH /usr/local/lib
 ---> Running in c5fe0c065886
Removing intermediate container c5fe0c065886
 ---> cae68e85cd6f
Step 21/24 : WORKDIR /opt/apromore/
 ---> Running in 8e209354e407
Removing intermediate container 8e209354e407
 ---> 324c69f95241
Step 22/24 : USER apromore
 ---> Running in efadd8cbf307
Removing intermediate container efadd8cbf307
 ---> 9d93eaeb8520
Step 23/24 : EXPOSE 9000
 ---> Running in 3aea9d5293b6
Removing intermediate container 3aea9d5293b6
 ---> 7fd2c7dca5a4
Step 24/24 : CMD [ "./virgo-tomcat-server-3.6.4.RELEASE/bin/startup.sh", "-clean" ]
 ---> Running in ae5e7fb8bd5d
Removing intermediate container ae5e7fb8bd5d
 ---> 8e2895590ff3

Successfully built 8e2895590ff3
Successfully tagged apromoredocker_apromore:latest
WARNING: Image for service apromore was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Building nirdizati_collator
Step 1/13 : FROM ubuntu:18.04
 ---> 4c108a37151f
Step 2/13 : RUN groupadd -r apromore && useradd --no-log-init -r -g apromore apromore
 ---> Using cache
 ---> eec9360ae6d2
Step 3/13 : RUN apt-get -y update && apt-get -y install git && apt-get -y install python3 && apt-get -y install python3-pip && apt-get -y clean
 ---> Using cache
 ---> f3fc5f05d48f
Step 4/13 : WORKDIR /opt/
 ---> Using cache
 ---> 6592049e40ff
Step 5/13 : RUN git clone https://github.com/nirdizati/nirdizati-training-backend.git
 ---> Using cache
 ---> 8f155fd8533e
Step 6/13 : WORKDIR /opt/nirdizati-training-backend/
 ---> Using cache
 ---> 90a603f3de40
Step 7/13 : RUN pip3 install -r requirements.txt
 ---> Using cache
 ---> ff8d998859ef
Step 8/13 : COPY retry.sh /opt/nirdizati-training-backend/apromore/
 ---> Using cache
 ---> c3622ab177ba
Step 9/13 : RUN chown -R apromore:apromore /opt/nirdizati-training-backend && chmod -R 777 /opt/nirdizati-training-backend
 ---> Using cache
 ---> e8ef91e6d928
Step 10/13 : ENV PYTHONPATH=/opt/nirdizati-training-backend:/opt/nirdizati-training-backend/core
 ---> Using cache
 ---> 2dd1de179e91
Step 11/13 : WORKDIR /opt/nirdizati-training-backend/apromore
 ---> Using cache
 ---> 90190ad06650
Step 12/13 : USER apromore
 ---> Using cache
 ---> e75daa3ebb9b
Step 13/13 : CMD [ "./retry.sh", "python3", "collate-events.py", "kafka:9092", "control", "events", "prefixes", "2" ]
 ---> Using cache
 ---> 6ec1b59bf1e8

Successfully built 6ec1b59bf1e8
Successfully tagged apromoredocker_nirdizati_collator:latest
WARNING: Image for service nirdizati_collator was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Building nirdizati_predict
Step 1/13 : FROM ubuntu:18.04
 ---> 4c108a37151f
Step 2/13 : RUN groupadd -r apromore && useradd --no-log-init -r -g apromore apromore
 ---> Using cache
 ---> eec9360ae6d2
Step 3/13 : RUN apt-get -y update && apt-get -y install git && apt-get -y install python3 && apt-get -y install python3-pip && apt-get -y clean
 ---> Using cache
 ---> f3fc5f05d48f
Step 4/13 : WORKDIR /opt/
 ---> Using cache
 ---> 6592049e40ff
Step 5/13 : RUN git clone https://github.com/nirdizati/nirdizati-training-backend.git
 ---> Using cache
 ---> 8f155fd8533e
Step 6/13 : WORKDIR /opt/nirdizati-training-backend/
 ---> Using cache
 ---> 90a603f3de40
Step 7/13 : RUN pip3 install -r requirements.txt
 ---> Using cache
 ---> ff8d998859ef
Step 8/13 : COPY retry.sh /opt/nirdizati-training-backend/apromore/
 ---> Using cache
 ---> c3622ab177ba
Step 9/13 : RUN chown -R apromore:apromore /opt/nirdizati-training-backend && chmod -R 777 /opt/nirdizati-training-backend
 ---> Using cache
 ---> e8ef91e6d928
Step 10/13 : ENV PYTHONPATH=/opt/nirdizati-training-backend:/opt/nirdizati-training-backend/core
 ---> Using cache
 ---> 2dd1de179e91
Step 11/13 : WORKDIR /opt/nirdizati-training-backend/apromore
 ---> Using cache
 ---> 90190ad06650
Step 12/13 : USER apromore
 ---> Using cache
 ---> e75daa3ebb9b
Step 13/13 : CMD [ "./retry.sh", "python3", "predict.py", "kafka:9092", "apromore:9000", "control", "prefixes", "predictions" ]
 ---> Using cache
 ---> 09db92b0dadd

Successfully built 09db92b0dadd
Successfully tagged apromoredocker_nirdizati_predict:latest
WARNING: Image for service nirdizati_predict was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Creating apromoredocker_mysql_1     ... done
Creating apromoredocker_zookeeper_1 ... done
Creating apromoredocker_kafka_1     ... done
Creating apromoredocker_nirdizati_predict_1  ... done
Creating apromoredocker_nirdizati_collator_1 ... done
Creating apromoredocker_apromore_1           ... done
Attaching to apromoredocker_mysql_1, apromoredocker_zookeeper_1, apromoredocker_kafka_1, apromoredocker_nirdizati_predict_1, apromoredocker_nirdizati_collator_1, apromoredocker_apromore_1
mysql_1               | 2019-07-23 13:59:44 0 [Warning] option 'max_allowed_packet': unsigned value 2147483648 adjusted to 1073741824
mysql_1               | 2019-07-23 13:59:44 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).
mysql_1               | 2019-07-23 13:59:44 0 [Note] mysqld (mysqld 5.6.44) starting as process 1 ...
mysql_1               | 2019-07-23 13:59:44 1 [Note] Plugin 'FEDERATED' is disabled.
zookeeper_1           | JMX enabled by default
kafka_1               | waiting for kafka to be ready
zookeeper_1           | Using config: /opt/zookeeper-3.4.6/bin/../conf/zoo.cfg
zookeeper_1           | 2019-07-23 13:59:45,519 [myid:] - INFO  [main:QuorumPeerConfig@103] - Reading configuration from: /opt/zookeeper-3.4.6/bin/../conf/zoo.cfg
mysql_1               | 2019-07-23 13:59:44 1 [Note] InnoDB: Using atomics to ref count buffer pool pages
mysql_1               | 2019-07-23 13:59:44 1 [Note] InnoDB: The InnoDB memory heap is disabled
mysql_1               | 2019-07-23 13:59:44 1 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins
mysql_1               | 2019-07-23 13:59:44 1 [Note] InnoDB: Memory barrier is not used
mysql_1               | 2019-07-23 13:59:44 1 [Note] InnoDB: Compressed tables use zlib 1.2.11
mysql_1               | 2019-07-23 13:59:44 1 [Note] InnoDB: Using Linux native AIO
zookeeper_1           | 2019-07-23 13:59:45,524 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
mysql_1               | 2019-07-23 13:59:44 1 [Note] InnoDB: Using CPU crc32 instructions
kafka_1               | [Configuring] 'advertised.port' in '/opt/kafka/config/server.properties'
mysql_1               | 2019-07-23 13:59:44 1 [Note] InnoDB: Initializing buffer pool, size = 128.0M
kafka_1               | Excluding KAFKA_HOME from broker config
mysql_1               | 2019-07-23 13:59:44 1 [Note] InnoDB: Completed initialization of buffer pool
zookeeper_1           | 2019-07-23 13:59:45,524 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
mysql_1               | 2019-07-23 13:59:44 1 [Note] InnoDB: Highest supported file format is Barracuda.
mysql_1               | 2019-07-23 13:59:44 1 [Note] InnoDB: 128 rollback segment(s) are active.
kafka_1               | [Configuring] 'advertised.host.name' in '/opt/kafka/config/server.properties'
zookeeper_1           | 2019-07-23 13:59:45,525 [myid:] - WARN  [main:QuorumPeerMain@113] - Either no config or no quorum defined in config, running  in standalone mode
kafka_1               | [Configuring] 'port' in '/opt/kafka/config/server.properties'
kafka_1               | [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
zookeeper_1           | 2019-07-23 13:59:45,525 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
kafka_1               | Excluding KAFKA_VERSION from broker config
zookeeper_1           | 2019-07-23 13:59:45,535 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
kafka_1               | [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
kafka_1               | [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
zookeeper_1           | 2019-07-23 13:59:45,539 [myid:] - INFO  [main:QuorumPeerConfig@103] - Reading configuration from: /opt/zookeeper-3.4.6/bin/../conf/zoo.cfg
mysql_1               | 2019-07-23 13:59:44 1 [Note] InnoDB: Waiting for purge to start
kafka_1               | [2019-07-23 13:59:47,154] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
zookeeper_1           | 2019-07-23 13:59:45,540 [myid:] - INFO  [main:ZooKeeperServerMain@95] - Starting server
mysql_1               | 2019-07-23 13:59:44 1 [Note] InnoDB: 5.6.44 started; log sequence number 741139078
zookeeper_1           | 2019-07-23 13:59:45,548 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
mysql_1               | Warning: World-writable config file './auto.cnf' is ignored
mysql_1               | 2019-07-23 13:59:44 1 [Warning] World-writable config file './auto.cnf' has been removed.
mysql_1               | 
mysql_1               | 2019-07-23 13:59:44 1 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 1fef931d-ad52-11e9-8d0d-0242ac1a0002.
zookeeper_1           | 2019-07-23 13:59:45,548 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=346af91e6d7a
mysql_1               | 2019-07-23 13:59:44 1 [Note] Server hostname (bind-address): '*'; port: 3306
zookeeper_1           | 2019-07-23 13:59:45,548 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
mysql_1               | 2019-07-23 13:59:44 1 [Note] IPv6 is available.
mysql_1               | 2019-07-23 13:59:44 1 [Note]   - '::' resolves to '::';
mysql_1               | 2019-07-23 13:59:44 1 [Note] Server socket created on IP: '::'.
zookeeper_1           | 2019-07-23 13:59:45,548 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
mysql_1               | 2019-07-23 13:59:44 1 [Warning] Insecure configuration for --pid-file: Location '/var/run/mysqld' in the path is accessible to all OS users. Consider choosing a different directory.
mysql_1               | 2019-07-23 13:59:44 1 [Warning] 'proxies_priv' entry '@ root@7e8eba850b09' ignored in --skip-name-resolve mode.
zookeeper_1           | 2019-07-23 13:59:45,548 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
mysql_1               | 2019-07-23 13:59:44 1 [Note] Event Scheduler: Loaded 0 events
mysql_1               | 2019-07-23 13:59:44 1 [Note] mysqld: ready for connections.
mysql_1               | Version: '5.6.44'  socket: '/var/run/mysqld/mysqld.sock'  port: 3306  MySQL Community Server (GPL)
zookeeper_1           | 2019-07-23 13:59:45,548 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.6/bin/../build/classes:/opt/zookeeper-3.4.6/bin/../build/lib/*.jar:/opt/zookeeper-3.4.6/bin/../lib/slf4j-log4j12-1.6.1.jar:/opt/zookeeper-3.4.6/bin/../lib/slf4j-api-1.6.1.jar:/opt/zookeeper-3.4.6/bin/../lib/netty-3.7.0.Final.jar:/opt/zookeeper-3.4.6/bin/../lib/log4j-1.2.16.jar:/opt/zookeeper-3.4.6/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.6/bin/../zookeeper-3.4.6.jar:/opt/zookeeper-3.4.6/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.6/bin/../conf:
zookeeper_1           | 2019-07-23 13:59:45,549 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
zookeeper_1           | 2019-07-23 13:59:45,549 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
zookeeper_1           | 2019-07-23 13:59:45,552 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
zookeeper_1           | 2019-07-23 13:59:45,552 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
zookeeper_1           | 2019-07-23 13:59:45,552 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
zookeeper_1           | 2019-07-23 13:59:45,552 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=4.18.0-25-generic
zookeeper_1           | 2019-07-23 13:59:45,552 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
zookeeper_1           | 2019-07-23 13:59:45,552 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
zookeeper_1           | 2019-07-23 13:59:45,552 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.6
zookeeper_1           | 2019-07-23 13:59:45,553 [myid:] - INFO  [main:ZooKeeperServer@755] - tickTime set to 2000
zookeeper_1           | 2019-07-23 13:59:45,554 [myid:] - INFO  [main:ZooKeeperServer@764] - minSessionTimeout set to -1
zookeeper_1           | 2019-07-23 13:59:45,554 [myid:] - INFO  [main:ZooKeeperServer@773] - maxSessionTimeout set to -1
zookeeper_1           | 2019-07-23 13:59:45,567 [myid:] - INFO  [main:NIOServerCnxnFactory@94] - binding to port 0.0.0.0/0.0.0.0:2181
kafka_1               | [2019-07-23 13:59:48,015] INFO starting (kafka.server.KafkaServer)
kafka_1               | [2019-07-23 13:59:48,017] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
kafka_1               | [2019-07-23 13:59:48,059] INFO [ZooKeeperClient] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
kafka_1               | [2019-07-23 13:59:48,068] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
kafka_1               | [2019-07-23 13:59:48,068] INFO Client environment:host.name=5803ed067b11 (org.apache.zookeeper.ZooKeeper)
kafka_1               | [2019-07-23 13:59:48,068] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
kafka_1               | [2019-07-23 13:59:48,068] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
kafka_1               | [2019-07-23 13:59:48,068] INFO Client environment:java.home=/usr/lib/jvm/java-1.8-openjdk/jre (org.apache.zookeeper.ZooKeeper)
kafka_1               | [2019-07-23 13:59:48,069] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-lang3-3.5.jar:/opt/kafka/bin/../libs/compileScala.mapping:/opt/kafka/bin/../libs/compileScala.mapping.asc:/opt/kafka/bin/../libs/connect-api-2.1.0.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.1.0.jar:/opt/kafka/bin/../libs/connect-file-2.1.0.jar:/opt/kafka/bin/../libs/connect-json-2.1.0.jar:/opt/kafka/bin/../libs/connect-runtime-2.1.0.jar:/opt/kafka/bin/../libs/connect-transforms-2.1.0.jar:/opt/kafka/bin/../libs/guava-20.0.jar:/opt/kafka/bin/../libs/hk2-api-2.5.0-b42.jar:/opt/kafka/bin/../libs/hk2-locator-2.5.0-b42.jar:/opt/kafka/bin/../libs/hk2-utils-2.5.0-b42.jar:/opt/kafka/bin/../libs/jackson-annotations-2.9.7.jar:/opt/kafka/bin/../libs/jackson-core-2.9.7.jar:/opt/kafka/bin/../libs/jackson-databind-2.9.7.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.9.7.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.9.7.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.9.7.jar:/opt/kafka/bin/../libs/javassist-3.22.0-CR2.jar:/opt/kafka/bin/../libs/javax.annotation-api-1.2.jar:/opt/kafka/bin/../libs/javax.inject-1.jar:/opt/kafka/bin/../libs/javax.inject-2.5.0-b42.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.27.jar:/opt/kafka/bin/../libs/jersey-common-2.27.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.27.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.27.jar:/opt/kafka/bin/../libs/jersey-hk2-2.27.jar:/opt/kafka/bin/../libs/jersey-media-jaxb-2.27.jar:/opt/kafka/bin/../libs/jersey-server-2.27.jar:/opt/kafka/bin/../libs/jetty-client-9.4.12.v20180830.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.12.v20180830.jar:/opt/kafka/bin/../libs/jetty-http-9.4.12.v20180830.jar:/opt/kafka/bin/../libs/jetty-io-9.4.12.v20180830.jar:/opt/kafka/bin/../libs/jetty-security-9.4.12.v20180830.jar:/opt/kafka/bin/../libs/jetty-server-9.4.12.v20180830.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.12.v20180830.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.12.v20180830.jar:/opt/kafka/bin/../libs/jetty-util-9.4.12.v20180830.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.1.0.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.1.0.jar:/opt/kafka/bin/../libs/kafka-streams-2.1.0.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.1.0.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.12-2.1.0.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.1.0.jar:/opt/kafka/bin/../libs/kafka-tools-2.1.0.jar:/opt/kafka/bin/../libs/kafka_2.12-2.1.0-sources.jar:/opt/kafka/bin/../libs/kafka_2.12-2.1.0.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.5.0.jar:/opt/kafka/bin/../libs/maven-artifact-3.5.4.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/opt/kafka/bin/../libs/plexus-utils-3.1.0.jar:/opt/kafka/bin/../libs/reflections-0.9.11.jar:/opt/kafka/bin/../libs/rocksdbjni-5.14.2.jar:/opt/kafka/bin/../libs/scala-library-2.12.7.jar:/opt/kafka/bin/../libs/scala-logging_2.12-3.9.0.jar:/opt/kafka/bin/../libs/scala-reflect-2.12.7.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.25.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.25.jar:/opt/kafka/bin/../libs/snappy-java-1.1.7.2.jar:/opt/kafka/bin/../libs/validation-api-1.1.0.Final.jar:/opt/kafka/bin/../libs/zkclient-0.10.jar:/opt/kafka/bin/../libs/zookeeper-3.4.13.jar:/opt/kafka/bin/../libs/zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
kafka_1               | [2019-07-23 13:59:48,070] INFO Client environment:java.library.path=/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64/server:/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/amd64:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
kafka_1               | [2019-07-23 13:59:48,070] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
kafka_1               | [2019-07-23 13:59:48,070] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
kafka_1               | [2019-07-23 13:59:48,070] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
kafka_1               | [2019-07-23 13:59:48,070] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
kafka_1               | [2019-07-23 13:59:48,070] INFO Client environment:os.version=4.18.0-25-generic (org.apache.zookeeper.ZooKeeper)
kafka_1               | [2019-07-23 13:59:48,070] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
kafka_1               | [2019-07-23 13:59:48,070] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
kafka_1               | [2019-07-23 13:59:48,070] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
kafka_1               | [2019-07-23 13:59:48,073] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@659a969b (org.apache.zookeeper.ZooKeeper)
kafka_1               | [2019-07-23 13:59:48,095] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
kafka_1               | [2019-07-23 13:59:48,097] INFO Opening socket connection to server zookeeper/172.26.0.3:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
kafka_1               | [2019-07-23 13:59:48,104] INFO Socket connection established to zookeeper/172.26.0.3:2181, initiating session (org.apache.zookeeper.ClientCnxn)
zookeeper_1           | 2019-07-23 13:59:48,106 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /172.26.0.4:37046
zookeeper_1           | 2019-07-23 13:59:48,115 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@868] - Client attempting to establish new session at /172.26.0.4:37046
zookeeper_1           | 2019-07-23 13:59:48,118 [myid:] - INFO  [SyncThread:0:FileTxnLog@199] - Creating new log file: log.1
zookeeper_1           | 2019-07-23 13:59:48,135 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@617] - Established session 0x16c1f2182af0000 with negotiated timeout 6000 for client /172.26.0.4:37046
kafka_1               | [2019-07-23 13:59:48,138] INFO Session establishment complete on server zookeeper/172.26.0.3:2181, sessionid = 0x16c1f2182af0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
kafka_1               | [2019-07-23 13:59:48,145] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
zookeeper_1           | 2019-07-23 13:59:48,251 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x16c1f2182af0000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
zookeeper_1           | 2019-07-23 13:59:48,264 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x16c1f2182af0000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
zookeeper_1           | 2019-07-23 13:59:48,274 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x16c1f2182af0000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
zookeeper_1           | 2019-07-23 13:59:48,649 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x16c1f2182af0000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
kafka_1               | [2019-07-23 13:59:48,659] INFO Cluster ID = 3kDlVU_PTDmYm2Q6Nytluw (kafka.server.KafkaServer)
kafka_1               | [2019-07-23 13:59:48,666] WARN No meta.properties file under dir /kafka/kafka-logs-5803ed067b11/meta.properties (kafka.server.BrokerMetadataCheckpoint)
kafka_1               | [2019-07-23 13:59:48,818] INFO KafkaConfig values: 
kafka_1               | 	advertised.host.name = kafka
kafka_1               | 	advertised.listeners = null
kafka_1               | 	advertised.port = 9092
kafka_1               | 	alter.config.policy.class.name = null
kafka_1               | 	alter.log.dirs.replication.quota.window.num = 11
kafka_1               | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafka_1               | 	authorizer.class.name = 
kafka_1               | 	auto.create.topics.enable = true
kafka_1               | 	auto.leader.rebalance.enable = true
kafka_1               | 	background.threads = 10
kafka_1               | 	broker.id = -1
kafka_1               | 	broker.id.generation.enable = true
kafka_1               | 	broker.rack = null
kafka_1               | 	client.quota.callback.class = null
kafka_1               | 	compression.type = producer
kafka_1               | 	connection.failed.authentication.delay.ms = 100
kafka_1               | 	connections.max.idle.ms = 600000
kafka_1               | 	controlled.shutdown.enable = true
kafka_1               | 	controlled.shutdown.max.retries = 3
kafka_1               | 	controlled.shutdown.retry.backoff.ms = 5000
kafka_1               | 	controller.socket.timeout.ms = 30000
kafka_1               | 	create.topic.policy.class.name = null
kafka_1               | 	default.replication.factor = 1
kafka_1               | 	delegation.token.expiry.check.interval.ms = 3600000
kafka_1               | 	delegation.token.expiry.time.ms = 86400000
kafka_1               | 	delegation.token.master.key = null
kafka_1               | 	delegation.token.max.lifetime.ms = 604800000
kafka_1               | 	delete.records.purgatory.purge.interval.requests = 1
kafka_1               | 	delete.topic.enable = true
kafka_1               | 	fetch.purgatory.purge.interval.requests = 1000
kafka_1               | 	group.initial.rebalance.delay.ms = 0
kafka_1               | 	group.max.session.timeout.ms = 300000
kafka_1               | 	group.min.session.timeout.ms = 6000
kafka_1               | 	host.name = 
kafka_1               | 	inter.broker.listener.name = null
kafka_1               | 	inter.broker.protocol.version = 2.1-IV2
kafka_1               | 	kafka.metrics.polling.interval.secs = 10
kafka_1               | 	kafka.metrics.reporters = []
kafka_1               | 	leader.imbalance.check.interval.seconds = 300
kafka_1               | 	leader.imbalance.per.broker.percentage = 10
kafka_1               | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
kafka_1               | 	listeners = null
kafka_1               | 	log.cleaner.backoff.ms = 15000
kafka_1               | 	log.cleaner.dedupe.buffer.size = 134217728
kafka_1               | 	log.cleaner.delete.retention.ms = 86400000
kafka_1               | 	log.cleaner.enable = true
kafka_1               | 	log.cleaner.io.buffer.load.factor = 0.9
kafka_1               | 	log.cleaner.io.buffer.size = 524288
kafka_1               | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka_1               | 	log.cleaner.min.cleanable.ratio = 0.5
kafka_1               | 	log.cleaner.min.compaction.lag.ms = 0
kafka_1               | 	log.cleaner.threads = 1
kafka_1               | 	log.cleanup.policy = [delete]
kafka_1               | 	log.dir = /tmp/kafka-logs
kafka_1               | 	log.dirs = /kafka/kafka-logs-5803ed067b11
kafka_1               | 	log.flush.interval.messages = 9223372036854775807
kafka_1               | 	log.flush.interval.ms = null
kafka_1               | 	log.flush.offset.checkpoint.interval.ms = 60000
kafka_1               | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafka_1               | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafka_1               | 	log.index.interval.bytes = 4096
kafka_1               | 	log.index.size.max.bytes = 10485760
kafka_1               | 	log.message.downconversion.enable = true
kafka_1               | 	log.message.format.version = 2.1-IV2
kafka_1               | 	log.message.timestamp.difference.max.ms = 9223372036854775807
kafka_1               | 	log.message.timestamp.type = CreateTime
kafka_1               | 	log.preallocate = false
kafka_1               | 	log.retention.bytes = -1
kafka_1               | 	log.retention.check.interval.ms = 300000
kafka_1               | 	log.retention.hours = 168
kafka_1               | 	log.retention.minutes = null
kafka_1               | 	log.retention.ms = null
kafka_1               | 	log.roll.hours = 168
kafka_1               | 	log.roll.jitter.hours = 0
kafka_1               | 	log.roll.jitter.ms = null
kafka_1               | 	log.roll.ms = null
kafka_1               | 	log.segment.bytes = 1073741824
kafka_1               | 	log.segment.delete.delay.ms = 60000
kafka_1               | 	max.connections.per.ip = 2147483647
kafka_1               | 	max.connections.per.ip.overrides = 
kafka_1               | 	max.incremental.fetch.session.cache.slots = 1000
kafka_1               | 	message.max.bytes = 1000012
kafka_1               | 	metric.reporters = []
kafka_1               | 	metrics.num.samples = 2
kafka_1               | 	metrics.recording.level = INFO
kafka_1               | 	metrics.sample.window.ms = 30000
kafka_1               | 	min.insync.replicas = 1
kafka_1               | 	num.io.threads = 8
kafka_1               | 	num.network.threads = 3
kafka_1               | 	num.partitions = 1
kafka_1               | 	num.recovery.threads.per.data.dir = 1
kafka_1               | 	num.replica.alter.log.dirs.threads = null
kafka_1               | 	num.replica.fetchers = 1
kafka_1               | 	offset.metadata.max.bytes = 4096
kafka_1               | 	offsets.commit.required.acks = -1
kafka_1               | 	offsets.commit.timeout.ms = 5000
kafka_1               | 	offsets.load.buffer.size = 5242880
kafka_1               | 	offsets.retention.check.interval.ms = 600000
kafka_1               | 	offsets.retention.minutes = 10080
kafka_1               | 	offsets.topic.compression.codec = 0
kafka_1               | 	offsets.topic.num.partitions = 50
kafka_1               | 	offsets.topic.replication.factor = 1
kafka_1               | 	offsets.topic.segment.bytes = 104857600
kafka_1               | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
kafka_1               | 	password.encoder.iterations = 4096
kafka_1               | 	password.encoder.key.length = 128
kafka_1               | 	password.encoder.keyfactory.algorithm = null
kafka_1               | 	password.encoder.old.secret = null
kafka_1               | 	password.encoder.secret = null
kafka_1               | 	port = 9092
kafka_1               | 	principal.builder.class = null
kafka_1               | 	producer.purgatory.purge.interval.requests = 1000
kafka_1               | 	queued.max.request.bytes = -1
kafka_1               | 	queued.max.requests = 500
kafka_1               | 	quota.consumer.default = 9223372036854775807
kafka_1               | 	quota.producer.default = 9223372036854775807
kafka_1               | 	quota.window.num = 11
kafka_1               | 	quota.window.size.seconds = 1
kafka_1               | 	replica.fetch.backoff.ms = 1000
kafka_1               | 	replica.fetch.max.bytes = 1048576
kafka_1               | 	replica.fetch.min.bytes = 1
kafka_1               | 	replica.fetch.response.max.bytes = 10485760
kafka_1               | 	replica.fetch.wait.max.ms = 500
kafka_1               | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafka_1               | 	replica.lag.time.max.ms = 10000
kafka_1               | 	replica.socket.receive.buffer.bytes = 65536
kafka_1               | 	replica.socket.timeout.ms = 30000
kafka_1               | 	replication.quota.window.num = 11
kafka_1               | 	replication.quota.window.size.seconds = 1
kafka_1               | 	request.timeout.ms = 30000
kafka_1               | 	reserved.broker.max.id = 1000
kafka_1               | 	sasl.client.callback.handler.class = null
kafka_1               | 	sasl.enabled.mechanisms = [GSSAPI]
kafka_1               | 	sasl.jaas.config = null
kafka_1               | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka_1               | 	sasl.kerberos.min.time.before.relogin = 60000
kafka_1               | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafka_1               | 	sasl.kerberos.service.name = null
kafka_1               | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka_1               | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka_1               | 	sasl.login.callback.handler.class = null
kafka_1               | 	sasl.login.class = null
kafka_1               | 	sasl.login.refresh.buffer.seconds = 300
kafka_1               | 	sasl.login.refresh.min.period.seconds = 60
kafka_1               | 	sasl.login.refresh.window.factor = 0.8
kafka_1               | 	sasl.login.refresh.window.jitter = 0.05
kafka_1               | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafka_1               | 	sasl.server.callback.handler.class = null
kafka_1               | 	security.inter.broker.protocol = PLAINTEXT
kafka_1               | 	socket.receive.buffer.bytes = 102400
kafka_1               | 	socket.request.max.bytes = 104857600
kafka_1               | 	socket.send.buffer.bytes = 102400
kafka_1               | 	ssl.cipher.suites = []
kafka_1               | 	ssl.client.auth = none
kafka_1               | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
kafka_1               | 	ssl.endpoint.identification.algorithm = https
kafka_1               | 	ssl.key.password = null
kafka_1               | 	ssl.keymanager.algorithm = SunX509
kafka_1               | 	ssl.keystore.location = null
kafka_1               | 	ssl.keystore.password = null
kafka_1               | 	ssl.keystore.type = JKS
kafka_1               | 	ssl.protocol = TLS
kafka_1               | 	ssl.provider = null
kafka_1               | 	ssl.secure.random.implementation = null
kafka_1               | 	ssl.trustmanager.algorithm = PKIX
kafka_1               | 	ssl.truststore.location = null
kafka_1               | 	ssl.truststore.password = null
kafka_1               | 	ssl.truststore.type = JKS
kafka_1               | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
kafka_1               | 	transaction.max.timeout.ms = 900000
kafka_1               | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafka_1               | 	transaction.state.log.load.buffer.size = 5242880
kafka_1               | 	transaction.state.log.min.isr = 1
kafka_1               | 	transaction.state.log.num.partitions = 50
kafka_1               | 	transaction.state.log.replication.factor = 1
kafka_1               | 	transaction.state.log.segment.bytes = 104857600
kafka_1               | 	transactional.id.expiration.ms = 604800000
kafka_1               | 	unclean.leader.election.enable = false
kafka_1               | 	zookeeper.connect = zookeeper:2181
kafka_1               | 	zookeeper.connection.timeout.ms = 6000
kafka_1               | 	zookeeper.max.in.flight.requests = 10
kafka_1               | 	zookeeper.session.timeout.ms = 6000
kafka_1               | 	zookeeper.set.acl = false
kafka_1               | 	zookeeper.sync.time.ms = 2000
kafka_1               |  (kafka.server.KafkaConfig)
kafka_1               | [2019-07-23 13:59:48,838] INFO KafkaConfig values: 
kafka_1               | 	advertised.host.name = kafka
kafka_1               | 	advertised.listeners = null
kafka_1               | 	advertised.port = 9092
kafka_1               | 	alter.config.policy.class.name = null
kafka_1               | 	alter.log.dirs.replication.quota.window.num = 11
kafka_1               | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafka_1               | 	authorizer.class.name = 
kafka_1               | 	auto.create.topics.enable = true
kafka_1               | 	auto.leader.rebalance.enable = true
kafka_1               | 	background.threads = 10
kafka_1               | 	broker.id = -1
kafka_1               | 	broker.id.generation.enable = true
kafka_1               | 	broker.rack = null
kafka_1               | 	client.quota.callback.class = null
kafka_1               | 	compression.type = producer
kafka_1               | 	connection.failed.authentication.delay.ms = 100
kafka_1               | 	connections.max.idle.ms = 600000
kafka_1               | 	controlled.shutdown.enable = true
kafka_1               | 	controlled.shutdown.max.retries = 3
kafka_1               | 	controlled.shutdown.retry.backoff.ms = 5000
kafka_1               | 	controller.socket.timeout.ms = 30000
kafka_1               | 	create.topic.policy.class.name = null
kafka_1               | 	default.replication.factor = 1
kafka_1               | 	delegation.token.expiry.check.interval.ms = 3600000
kafka_1               | 	delegation.token.expiry.time.ms = 86400000
kafka_1               | 	delegation.token.master.key = null
kafka_1               | 	delegation.token.max.lifetime.ms = 604800000
kafka_1               | 	delete.records.purgatory.purge.interval.requests = 1
kafka_1               | 	delete.topic.enable = true
kafka_1               | 	fetch.purgatory.purge.interval.requests = 1000
kafka_1               | 	group.initial.rebalance.delay.ms = 0
kafka_1               | 	group.max.session.timeout.ms = 300000
kafka_1               | 	group.min.session.timeout.ms = 6000
kafka_1               | 	host.name = 
kafka_1               | 	inter.broker.listener.name = null
kafka_1               | 	inter.broker.protocol.version = 2.1-IV2
kafka_1               | 	kafka.metrics.polling.interval.secs = 10
kafka_1               | 	kafka.metrics.reporters = []
kafka_1               | 	leader.imbalance.check.interval.seconds = 300
kafka_1               | 	leader.imbalance.per.broker.percentage = 10
kafka_1               | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
kafka_1               | 	listeners = null
kafka_1               | 	log.cleaner.backoff.ms = 15000
kafka_1               | 	log.cleaner.dedupe.buffer.size = 134217728
kafka_1               | 	log.cleaner.delete.retention.ms = 86400000
kafka_1               | 	log.cleaner.enable = true
kafka_1               | 	log.cleaner.io.buffer.load.factor = 0.9
kafka_1               | 	log.cleaner.io.buffer.size = 524288
kafka_1               | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka_1               | 	log.cleaner.min.cleanable.ratio = 0.5
kafka_1               | 	log.cleaner.min.compaction.lag.ms = 0
kafka_1               | 	log.cleaner.threads = 1
kafka_1               | 	log.cleanup.policy = [delete]
kafka_1               | 	log.dir = /tmp/kafka-logs
kafka_1               | 	log.dirs = /kafka/kafka-logs-5803ed067b11
kafka_1               | 	log.flush.interval.messages = 9223372036854775807
kafka_1               | 	log.flush.interval.ms = null
kafka_1               | 	log.flush.offset.checkpoint.interval.ms = 60000
kafka_1               | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafka_1               | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafka_1               | 	log.index.interval.bytes = 4096
kafka_1               | 	log.index.size.max.bytes = 10485760
kafka_1               | 	log.message.downconversion.enable = true
kafka_1               | 	log.message.format.version = 2.1-IV2
kafka_1               | 	log.message.timestamp.difference.max.ms = 9223372036854775807
kafka_1               | 	log.message.timestamp.type = CreateTime
kafka_1               | 	log.preallocate = false
kafka_1               | 	log.retention.bytes = -1
kafka_1               | 	log.retention.check.interval.ms = 300000
kafka_1               | 	log.retention.hours = 168
kafka_1               | 	log.retention.minutes = null
kafka_1               | 	log.retention.ms = null
kafka_1               | 	log.roll.hours = 168
kafka_1               | 	log.roll.jitter.hours = 0
kafka_1               | 	log.roll.jitter.ms = null
kafka_1               | 	log.roll.ms = null
kafka_1               | 	log.segment.bytes = 1073741824
kafka_1               | 	log.segment.delete.delay.ms = 60000
kafka_1               | 	max.connections.per.ip = 2147483647
kafka_1               | 	max.connections.per.ip.overrides = 
kafka_1               | 	max.incremental.fetch.session.cache.slots = 1000
kafka_1               | 	message.max.bytes = 1000012
kafka_1               | 	metric.reporters = []
kafka_1               | 	metrics.num.samples = 2
kafka_1               | 	metrics.recording.level = INFO
kafka_1               | 	metrics.sample.window.ms = 30000
kafka_1               | 	min.insync.replicas = 1
kafka_1               | 	num.io.threads = 8
kafka_1               | 	num.network.threads = 3
kafka_1               | 	num.partitions = 1
kafka_1               | 	num.recovery.threads.per.data.dir = 1
kafka_1               | 	num.replica.alter.log.dirs.threads = null
kafka_1               | 	num.replica.fetchers = 1
kafka_1               | 	offset.metadata.max.bytes = 4096
kafka_1               | 	offsets.commit.required.acks = -1
kafka_1               | 	offsets.commit.timeout.ms = 5000
kafka_1               | 	offsets.load.buffer.size = 5242880
kafka_1               | 	offsets.retention.check.interval.ms = 600000
kafka_1               | 	offsets.retention.minutes = 10080
kafka_1               | 	offsets.topic.compression.codec = 0
kafka_1               | 	offsets.topic.num.partitions = 50
kafka_1               | 	offsets.topic.replication.factor = 1
kafka_1               | 	offsets.topic.segment.bytes = 104857600
kafka_1               | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
kafka_1               | 	password.encoder.iterations = 4096
kafka_1               | 	password.encoder.key.length = 128
kafka_1               | 	password.encoder.keyfactory.algorithm = null
kafka_1               | 	password.encoder.old.secret = null
kafka_1               | 	password.encoder.secret = null
kafka_1               | 	port = 9092
kafka_1               | 	principal.builder.class = null
kafka_1               | 	producer.purgatory.purge.interval.requests = 1000
kafka_1               | 	queued.max.request.bytes = -1
kafka_1               | 	queued.max.requests = 500
kafka_1               | 	quota.consumer.default = 9223372036854775807
kafka_1               | 	quota.producer.default = 9223372036854775807
kafka_1               | 	quota.window.num = 11
kafka_1               | 	quota.window.size.seconds = 1
kafka_1               | 	replica.fetch.backoff.ms = 1000
kafka_1               | 	replica.fetch.max.bytes = 1048576
kafka_1               | 	replica.fetch.min.bytes = 1
kafka_1               | 	replica.fetch.response.max.bytes = 10485760
kafka_1               | 	replica.fetch.wait.max.ms = 500
kafka_1               | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafka_1               | 	replica.lag.time.max.ms = 10000
kafka_1               | 	replica.socket.receive.buffer.bytes = 65536
kafka_1               | 	replica.socket.timeout.ms = 30000
kafka_1               | 	replication.quota.window.num = 11
kafka_1               | 	replication.quota.window.size.seconds = 1
kafka_1               | 	request.timeout.ms = 30000
kafka_1               | 	reserved.broker.max.id = 1000
kafka_1               | 	sasl.client.callback.handler.class = null
kafka_1               | 	sasl.enabled.mechanisms = [GSSAPI]
kafka_1               | 	sasl.jaas.config = null
kafka_1               | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka_1               | 	sasl.kerberos.min.time.before.relogin = 60000
kafka_1               | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafka_1               | 	sasl.kerberos.service.name = null
kafka_1               | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka_1               | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka_1               | 	sasl.login.callback.handler.class = null
kafka_1               | 	sasl.login.class = null
kafka_1               | 	sasl.login.refresh.buffer.seconds = 300
kafka_1               | 	sasl.login.refresh.min.period.seconds = 60
kafka_1               | 	sasl.login.refresh.window.factor = 0.8
kafka_1               | 	sasl.login.refresh.window.jitter = 0.05
kafka_1               | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafka_1               | 	sasl.server.callback.handler.class = null
kafka_1               | 	security.inter.broker.protocol = PLAINTEXT
kafka_1               | 	socket.receive.buffer.bytes = 102400
kafka_1               | 	socket.request.max.bytes = 104857600
kafka_1               | 	socket.send.buffer.bytes = 102400
kafka_1               | 	ssl.cipher.suites = []
kafka_1               | 	ssl.client.auth = none
kafka_1               | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
kafka_1               | 	ssl.endpoint.identification.algorithm = https
kafka_1               | 	ssl.key.password = null
kafka_1               | 	ssl.keymanager.algorithm = SunX509
kafka_1               | 	ssl.keystore.location = null
kafka_1               | 	ssl.keystore.password = null
kafka_1               | 	ssl.keystore.type = JKS
kafka_1               | 	ssl.protocol = TLS
kafka_1               | 	ssl.provider = null
kafka_1               | 	ssl.secure.random.implementation = null
kafka_1               | 	ssl.trustmanager.algorithm = PKIX
kafka_1               | 	ssl.truststore.location = null
kafka_1               | 	ssl.truststore.password = null
kafka_1               | 	ssl.truststore.type = JKS
kafka_1               | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
kafka_1               | 	transaction.max.timeout.ms = 900000
kafka_1               | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafka_1               | 	transaction.state.log.load.buffer.size = 5242880
kafka_1               | 	transaction.state.log.min.isr = 1
kafka_1               | 	transaction.state.log.num.partitions = 50
kafka_1               | 	transaction.state.log.replication.factor = 1
kafka_1               | 	transaction.state.log.segment.bytes = 104857600
kafka_1               | 	transactional.id.expiration.ms = 604800000
kafka_1               | 	unclean.leader.election.enable = false
kafka_1               | 	zookeeper.connect = zookeeper:2181
kafka_1               | 	zookeeper.connection.timeout.ms = 6000
kafka_1               | 	zookeeper.max.in.flight.requests = 10
kafka_1               | 	zookeeper.session.timeout.ms = 6000
kafka_1               | 	zookeeper.set.acl = false
kafka_1               | 	zookeeper.sync.time.ms = 2000
kafka_1               |  (kafka.server.KafkaConfig)
kafka_1               | [2019-07-23 13:59:48,879] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka_1               | [2019-07-23 13:59:48,879] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka_1               | [2019-07-23 13:59:48,880] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka_1               | [2019-07-23 13:59:48,913] INFO Log directory /kafka/kafka-logs-5803ed067b11 not found, creating it. (kafka.log.LogManager)
kafka_1               | [2019-07-23 13:59:48,923] INFO Loading logs. (kafka.log.LogManager)
kafka_1               | [2019-07-23 13:59:48,934] INFO Logs loading complete in 11 ms. (kafka.log.LogManager)
kafka_1               | [2019-07-23 13:59:48,958] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
kafka_1               | [2019-07-23 13:59:48,962] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
kafka_1               | [2019-07-23 13:59:49,441] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
kafka_1               | [2019-07-23 13:59:49,486] INFO [SocketServer brokerId=1001] Started 1 acceptor threads (kafka.network.SocketServer)
kafka_1               | [2019-07-23 13:59:49,529] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1               | [2019-07-23 13:59:49,533] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1               | [2019-07-23 13:59:49,539] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1               | [2019-07-23 13:59:49,603] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
kafka_1               | [2019-07-23 13:59:49,640] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
kafka_1               | [2019-07-23 13:59:49,644] INFO Result of znode creation at /brokers/ids/1001 is: OK (kafka.zk.KafkaZkClient)
kafka_1               | [2019-07-23 13:59:49,646] INFO Registered broker 1001 at path /brokers/ids/1001 with addresses: ArrayBuffer(EndPoint(kafka,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
kafka_1               | [2019-07-23 13:59:49,650] WARN No meta.properties file under dir /kafka/kafka-logs-5803ed067b11/meta.properties (kafka.server.BrokerMetadataCheckpoint)
kafka_1               | [2019-07-23 13:59:49,763] INFO [ExpirationReaper-1001-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1               | [2019-07-23 13:59:49,788] INFO [ExpirationReaper-1001-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1               | [2019-07-23 13:59:49,789] INFO [ExpirationReaper-1001-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1               | [2019-07-23 13:59:49,790] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
kafka_1               | [2019-07-23 13:59:49,829] INFO [GroupCoordinator 1001]: Starting up. (kafka.coordinator.group.GroupCoordinator)
kafka_1               | [2019-07-23 13:59:49,831] INFO [GroupCoordinator 1001]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
kafka_1               | [2019-07-23 13:59:49,838] INFO [GroupMetadataManager brokerId=1001] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 13:59:49,848] INFO [ProducerId Manager 1001]: Acquired new producerId block (brokerId:1001,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
kafka_1               | [2019-07-23 13:59:49,884] INFO [TransactionCoordinator id=1001] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
kafka_1               | [2019-07-23 13:59:49,887] INFO [Transaction Marker Channel Manager 1001]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
kafka_1               | [2019-07-23 13:59:49,887] INFO [TransactionCoordinator id=1001] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
kafka_1               | [2019-07-23 13:59:49,979] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
zookeeper_1           | 2019-07-23 13:59:49,987 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@592] - Got user-level KeeperException when processing sessionid:0x16c1f2182af0000 type:multi cxid:0x31 zxid:0x1d txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
zookeeper_1           | 2019-07-23 13:59:50,012 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@592] - Got user-level KeeperException when processing sessionid:0x16c1f2182af0000 type:multi cxid:0x37 zxid:0x1e txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
kafka_1               | [2019-07-23 13:59:50,050] INFO [SocketServer brokerId=1001] Started processors for 1 acceptors (kafka.network.SocketServer)
kafka_1               | [2019-07-23 13:59:50,060] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
kafka_1               | [2019-07-23 13:59:50,060] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
kafka_1               | [2019-07-23 13:59:50,063] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)
apromore_1            | [2019-07-23 13:59:50.404] startup-tracker              <KE0001I> Kernel starting. 
apromore_1            | [2019-07-23 13:59:55.517] startup-tracker              <KE0002I> Kernel started. 
apromore_1            | [2019-07-23 13:59:55.683] system-artifacts             <DE0000I> Installing plan 'org.eclipse.virgo.kernel.userregion.blueprint' version '3.6.4'. 
apromore_1            | [2019-07-23 13:59:55.760] system-artifacts             <DE0000I> Installing bundle 'org.eclipse.gemini.blueprint.core' version '1.0.2.RELEASE'. 
apromore_1            | [2019-07-23 13:59:55.781] system-artifacts             <DE0000I> Installing bundle 'org.eclipse.gemini.blueprint.extender' version '1.0.2.RELEASE'. 
apromore_1            | [2019-07-23 13:59:55.791] system-artifacts             <DE0000I> Installing bundle 'org.eclipse.gemini.blueprint.io' version '1.0.2.RELEASE'. 
kafka_1               | creating topics: events:1:1
kafka_1               | creating topics: prefixes:1:1
kafka_1               | creating topics: predictions:1:1
kafka_1               | creating topics: control:1:1
apromore_1            | [2019-07-23 13:59:55.801] system-artifacts             <DE0000I> Installing bundle 'org.eclipse.virgo.kernel.agent.dm' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 13:59:55.817] system-artifacts             <DE0000I> Installing bundle 'org.eclipse.virgo.kernel.deployer.dm' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 13:59:55.842] system-artifacts             <DE0000I> Installing bundle 'org.eclipse.equinox.ds' version '1.4.0.v20120112-1400'. 
apromore_1            | [2019-07-23 13:59:55.859] system-artifacts             <DE0000I> Installing bundle 'org.eclipse.equinox.util' version '1.0.300.v20111010-1614'. 
apromore_1            | [2019-07-23 13:59:55.865] system-artifacts             <DE0000I> Installing configuration 'osgi.console' version '0.0.0'. 
zookeeper_1           | 2019-07-23 13:59:58,101 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x16c1f2182af0000 type:setData cxid:0x44 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/config/topics/events Error:KeeperErrorCode = NoNode for /config/topics/events
zookeeper_1           | 2019-07-23 13:59:58,103 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x16c1f2182af0000 type:setData cxid:0x45 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/config/topics/control Error:KeeperErrorCode = NoNode for /config/topics/control
kafka_1               | [2019-07-23 13:59:58,115] INFO Topic creation Map(events-0 -> ArrayBuffer(1001)) (kafka.zk.AdminZkClient)
kafka_1               | [2019-07-23 13:59:58,134] INFO Topic creation Map(control-0 -> ArrayBuffer(1001)) (kafka.zk.AdminZkClient)
kafka_1               | [2019-07-23 13:59:58,159] INFO [KafkaApi-1001] Auto creation of topic events with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
kafka_1               | [2019-07-23 13:59:58,160] INFO [KafkaApi-1001] Auto creation of topic control with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
kafka_1               | [2019-07-23 13:59:58,586] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions Set(control-0, events-0) (kafka.server.ReplicaFetcherManager)
kafka_1               | [2019-07-23 13:59:58,813] INFO [Log partition=control-0, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 13:59:58,834] INFO [Log partition=control-0, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 116 ms (kafka.log.Log)
kafka_1               | [2019-07-23 13:59:58,842] INFO Created log for partition control-0 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 13:59:58,844] INFO [Partition control-0 broker=1001] No checkpointed highwatermark is found for partition control-0 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 13:59:58,865] INFO Replica loaded for partition control-0 with initial high watermark 0 (kafka.cluster.Replica)
zookeeper_1           | 2019-07-23 13:59:58,899 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x16c1f2182af0000 type:setData cxid:0x5b zxid:0x2b txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
kafka_1               | [2019-07-23 13:59:58,905] INFO [Partition control-0 broker=1001] control-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 13:59:58,934] INFO Topic creation Map(__consumer_offsets-22 -> ArrayBuffer(1001), __consumer_offsets-30 -> ArrayBuffer(1001), __consumer_offsets-8 -> ArrayBuffer(1001), __consumer_offsets-21 -> ArrayBuffer(1001), __consumer_offsets-4 -> ArrayBuffer(1001), __consumer_offsets-27 -> ArrayBuffer(1001), __consumer_offsets-7 -> ArrayBuffer(1001), __consumer_offsets-9 -> ArrayBuffer(1001), __consumer_offsets-46 -> ArrayBuffer(1001), __consumer_offsets-25 -> ArrayBuffer(1001), __consumer_offsets-35 -> ArrayBuffer(1001), __consumer_offsets-41 -> ArrayBuffer(1001), __consumer_offsets-33 -> ArrayBuffer(1001), __consumer_offsets-23 -> ArrayBuffer(1001), __consumer_offsets-49 -> ArrayBuffer(1001), __consumer_offsets-47 -> ArrayBuffer(1001), __consumer_offsets-16 -> ArrayBuffer(1001), __consumer_offsets-28 -> ArrayBuffer(1001), __consumer_offsets-31 -> ArrayBuffer(1001), __consumer_offsets-36 -> ArrayBuffer(1001), __consumer_offsets-42 -> ArrayBuffer(1001), __consumer_offsets-3 -> ArrayBuffer(1001), __consumer_offsets-18 -> ArrayBuffer(1001), __consumer_offsets-37 -> ArrayBuffer(1001), __consumer_offsets-15 -> ArrayBuffer(1001), __consumer_offsets-24 -> ArrayBuffer(1001), __consumer_offsets-38 -> ArrayBuffer(1001), __consumer_offsets-17 -> ArrayBuffer(1001), __consumer_offsets-48 -> ArrayBuffer(1001), __consumer_offsets-19 -> ArrayBuffer(1001), __consumer_offsets-11 -> ArrayBuffer(1001), __consumer_offsets-13 -> ArrayBuffer(1001), __consumer_offsets-2 -> ArrayBuffer(1001), __consumer_offsets-43 -> ArrayBuffer(1001), __consumer_offsets-6 -> ArrayBuffer(1001), __consumer_offsets-14 -> ArrayBuffer(1001), __consumer_offsets-20 -> ArrayBuffer(1001), __consumer_offsets-0 -> ArrayBuffer(1001), __consumer_offsets-44 -> ArrayBuffer(1001), __consumer_offsets-39 -> ArrayBuffer(1001), __consumer_offsets-12 -> ArrayBuffer(1001), __consumer_offsets-45 -> ArrayBuffer(1001), __consumer_offsets-1 -> ArrayBuffer(1001), __consumer_offsets-5 -> ArrayBuffer(1001), __consumer_offsets-26 -> ArrayBuffer(1001), __consumer_offsets-29 -> ArrayBuffer(1001), __consumer_offsets-34 -> ArrayBuffer(1001), __consumer_offsets-10 -> ArrayBuffer(1001), __consumer_offsets-32 -> ArrayBuffer(1001), __consumer_offsets-40 -> ArrayBuffer(1001)) (kafka.zk.AdminZkClient)
kafka_1               | [2019-07-23 13:59:58,956] INFO [KafkaApi-1001] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
zookeeper_1           | 2019-07-23 13:59:58,974 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x16c1f2182af0000 type:setData cxid:0x63 zxid:0x2e txntype:-1 reqpath:n/a Error Path:/config/topics/prefixes Error:KeeperErrorCode = NoNode for /config/topics/prefixes
kafka_1               | [2019-07-23 13:59:58,998] INFO Topic creation Map(prefixes-0 -> ArrayBuffer(1001)) (kafka.zk.AdminZkClient)
kafka_1               | [2019-07-23 13:59:59,021] INFO [KafkaApi-1001] Auto creation of topic prefixes with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
kafka_1               | [2019-07-23 13:59:59,052] INFO [Log partition=events-0, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 13:59:59,054] INFO [Log partition=events-0, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
kafka_1               | [2019-07-23 13:59:59,056] INFO Created log for partition events-0 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 13:59:59,057] INFO [Partition events-0 broker=1001] No checkpointed highwatermark is found for partition events-0 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 13:59:59,058] INFO Replica loaded for partition events-0 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 13:59:59,059] INFO [Partition events-0 broker=1001] events-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 13:59:59,714] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
kafka_1               | [2019-07-23 13:59:59,738] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 13:59:59,754] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
kafka_1               | [2019-07-23 13:59:59,758] INFO Created log for partition __consumer_offsets-0 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 13:59:59,799] INFO [Partition __consumer_offsets-0 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 13:59:59,812] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 13:59:59,814] INFO [Partition __consumer_offsets-0 broker=1001] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 13:59:59,838] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 13:59:59,839] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
kafka_1               | [2019-07-23 13:59:59,841] INFO Created log for partition __consumer_offsets-29 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 13:59:59,843] INFO [Partition __consumer_offsets-29 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 13:59:59,844] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 13:59:59,845] INFO [Partition __consumer_offsets-29 broker=1001] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 13:59:59,861] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 13:59:59,866] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
kafka_1               | [2019-07-23 13:59:59,868] INFO Created log for partition __consumer_offsets-48 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 13:59:59,870] INFO [Partition __consumer_offsets-48 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 13:59:59,877] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 13:59:59,878] INFO [Partition __consumer_offsets-48 broker=1001] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 13:59:59,893] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 13:59:59,895] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
kafka_1               | [2019-07-23 13:59:59,897] INFO Created log for partition __consumer_offsets-10 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 13:59:59,899] INFO [Partition __consumer_offsets-10 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 13:59:59,899] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 13:59:59,900] INFO [Partition __consumer_offsets-10 broker=1001] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 13:59:59,934] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 13:59:59,937] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
kafka_1               | [2019-07-23 13:59:59,985] INFO Created log for partition __consumer_offsets-45 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 13:59:59,986] INFO [Partition __consumer_offsets-45 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 13:59:59,986] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 13:59:59,986] INFO [Partition __consumer_offsets-45 broker=1001] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,030] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,034] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,036] INFO Created log for partition __consumer_offsets-26 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,038] INFO [Partition __consumer_offsets-26 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,039] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,040] INFO [Partition __consumer_offsets-26 broker=1001] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,053] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,054] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,055] INFO Created log for partition __consumer_offsets-7 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,056] INFO [Partition __consumer_offsets-7 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,056] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,058] INFO [Partition __consumer_offsets-7 broker=1001] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,073] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,075] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,077] INFO Created log for partition __consumer_offsets-42 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,079] INFO [Partition __consumer_offsets-42 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,080] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,081] INFO [Partition __consumer_offsets-42 broker=1001] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,102] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,108] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,110] INFO Created log for partition __consumer_offsets-4 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,111] INFO [Partition __consumer_offsets-4 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,118] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,119] INFO [Partition __consumer_offsets-4 broker=1001] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,135] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,151] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,157] INFO Created log for partition __consumer_offsets-23 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,158] INFO [Partition __consumer_offsets-23 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,158] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,159] INFO [Partition __consumer_offsets-23 broker=1001] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,187] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,187] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,199] INFO Created log for partition __consumer_offsets-1 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,199] INFO [Partition __consumer_offsets-1 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,202] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,204] INFO [Partition __consumer_offsets-1 broker=1001] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,236] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,240] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,241] INFO Created log for partition __consumer_offsets-20 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,244] INFO [Partition __consumer_offsets-20 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,244] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,245] INFO [Partition __consumer_offsets-20 broker=1001] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,256] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,259] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,266] INFO Created log for partition __consumer_offsets-39 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,269] INFO [Partition __consumer_offsets-39 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,270] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,271] INFO [Partition __consumer_offsets-39 broker=1001] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,290] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,293] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,299] INFO Created log for partition __consumer_offsets-17 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,300] INFO [Partition __consumer_offsets-17 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,300] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,301] INFO [Partition __consumer_offsets-17 broker=1001] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,325] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,326] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,328] INFO Created log for partition __consumer_offsets-36 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,335] INFO [Partition __consumer_offsets-36 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,335] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,336] INFO [Partition __consumer_offsets-36 broker=1001] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
zookeeper_1           | 2019-07-23 14:00:00,358 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /172.26.0.4:37088
kafka_1               | [2019-07-23 14:00:00,366] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
zookeeper_1           | 2019-07-23 14:00:00,369 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@868] - Client attempting to establish new session at /172.26.0.4:37088
kafka_1               | [2019-07-23 14:00:00,370] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
zookeeper_1           | 2019-07-23 14:00:00,372 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@617] - Established session 0x16c1f2182af0001 with negotiated timeout 30000 for client /172.26.0.4:37088
kafka_1               | [2019-07-23 14:00:00,396] INFO Created log for partition __consumer_offsets-14 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,398] INFO [Partition __consumer_offsets-14 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,398] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,398] INFO [Partition __consumer_offsets-14 broker=1001] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,425] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,427] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,438] INFO Created log for partition __consumer_offsets-33 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,451] INFO [Partition __consumer_offsets-33 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,451] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,451] INFO [Partition __consumer_offsets-33 broker=1001] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,474] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,475] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,477] INFO Created log for partition __consumer_offsets-49 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,478] INFO [Partition __consumer_offsets-49 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,478] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,479] INFO [Partition __consumer_offsets-49 broker=1001] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
apromore_1            | [2019-07-23 14:00:00.491] system-artifacts             <DE0001I> Installed bundle 'org.eclipse.gemini.blueprint.core' version '1.0.2.RELEASE'. 
apromore_1            | [2019-07-23 14:00:00.493] system-artifacts             <DE0001I> Installed bundle 'org.eclipse.gemini.blueprint.extender' version '1.0.2.RELEASE'. 
apromore_1            | [2019-07-23 14:00:00.497] system-artifacts             <DE0001I> Installed bundle 'org.eclipse.gemini.blueprint.io' version '1.0.2.RELEASE'. 
kafka_1               | [2019-07-23 14:00:00,496] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,501] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
apromore_1            | [2019-07-23 14:00:00.505] system-artifacts             <DE0001I> Installed bundle 'org.eclipse.virgo.kernel.agent.dm' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:00.507] system-artifacts             <DE0001I> Installed bundle 'org.eclipse.virgo.kernel.deployer.dm' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:00.508] system-artifacts             <DE0001I> Installed bundle 'org.eclipse.equinox.ds' version '1.4.0.v20120112-1400'. 
apromore_1            | [2019-07-23 14:00:00.510] system-artifacts             <DE0001I> Installed bundle 'org.eclipse.equinox.util' version '1.0.300.v20111010-1614'. 
apromore_1            | [2019-07-23 14:00:00.511] system-artifacts             <DE0001I> Installed configuration 'osgi.console' version '0.0.0'. 
apromore_1            | [2019-07-23 14:00:00.512] system-artifacts             <DE0001I> Installed plan 'org.eclipse.virgo.kernel.userregion.blueprint' version '3.6.4'. 
zookeeper_1           | 2019-07-23 14:00:00,542 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /172.26.0.4:37090
zookeeper_1           | 2019-07-23 14:00:00,566 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@868] - Client attempting to establish new session at /172.26.0.4:37090
zookeeper_1           | 2019-07-23 14:00:00,569 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@617] - Established session 0x16c1f2182af0002 with negotiated timeout 30000 for client /172.26.0.4:37090
apromore_1            | [2019-07-23 14:00:00.586] system-artifacts             <DE0004I> Starting plan 'org.eclipse.virgo.kernel.userregion.blueprint' version '3.6.4'. 
kafka_1               | [2019-07-23 14:00:00,586] INFO Created log for partition __consumer_offsets-11 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,588] INFO [Partition __consumer_offsets-11 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,588] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,588] INFO [Partition __consumer_offsets-11 broker=1001] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
apromore_1            | [2019-07-23 14:00:00.599] system-artifacts             <DE0004I> Starting bundle 'org.eclipse.gemini.blueprint.core' version '1.0.2.RELEASE'. 
apromore_1            | [2019-07-23 14:00:00.603] start-signalling-1           <DE0005I> Started bundle 'org.eclipse.gemini.blueprint.core' version '1.0.2.RELEASE'. 
kafka_1               | [2019-07-23 14:00:00,607] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,609] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
apromore_1            | [2019-07-23 14:00:00.609] system-artifacts             <DE0004I> Starting bundle 'org.eclipse.gemini.blueprint.extender' version '1.0.2.RELEASE'. 
kafka_1               | [2019-07-23 14:00:00,610] INFO Created log for partition __consumer_offsets-30 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,611] INFO [Partition __consumer_offsets-30 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,611] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,611] INFO [Partition __consumer_offsets-30 broker=1001] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,621] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,622] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,628] INFO Created log for partition __consumer_offsets-46 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,631] INFO [Partition __consumer_offsets-46 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,632] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,633] INFO [Partition __consumer_offsets-46 broker=1001] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,648] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,652] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,656] INFO Created log for partition __consumer_offsets-27 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,658] INFO [Partition __consumer_offsets-27 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,659] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,659] INFO [Partition __consumer_offsets-27 broker=1001] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,672] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,673] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,677] INFO Created log for partition __consumer_offsets-8 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,678] INFO [Partition __consumer_offsets-8 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,679] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,680] INFO [Partition __consumer_offsets-8 broker=1001] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,725] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,726] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,728] INFO Created log for partition __consumer_offsets-24 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
zookeeper_1           | 2019-07-23 14:00:00,729 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /172.26.0.4:37092
kafka_1               | [2019-07-23 14:00:00,733] INFO [Partition __consumer_offsets-24 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,734] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,735] INFO [Partition __consumer_offsets-24 broker=1001] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
zookeeper_1           | 2019-07-23 14:00:00,769 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@868] - Client attempting to establish new session at /172.26.0.4:37092
zookeeper_1           | 2019-07-23 14:00:00,773 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@617] - Established session 0x16c1f2182af0003 with negotiated timeout 30000 for client /172.26.0.4:37092
kafka_1               | [2019-07-23 14:00:00,778] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,786] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,789] INFO Created log for partition __consumer_offsets-43 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,791] INFO [Partition __consumer_offsets-43 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,791] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,791] INFO [Partition __consumer_offsets-43 broker=1001] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,805] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,807] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,808] INFO Created log for partition __consumer_offsets-5 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,809] INFO [Partition __consumer_offsets-5 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,810] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,810] INFO [Partition __consumer_offsets-5 broker=1001] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,872] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,874] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,875] INFO Created log for partition __consumer_offsets-21 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,876] INFO [Partition __consumer_offsets-21 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,877] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,878] INFO [Partition __consumer_offsets-21 broker=1001] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,892] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,897] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,899] INFO Created log for partition __consumer_offsets-2 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,900] INFO [Partition __consumer_offsets-2 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,900] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,901] INFO [Partition __consumer_offsets-2 broker=1001] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,917] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,917] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,919] INFO Created log for partition __consumer_offsets-40 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,919] INFO [Partition __consumer_offsets-40 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,919] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,920] INFO [Partition __consumer_offsets-40 broker=1001] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,966] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,969] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,971] INFO Created log for partition __consumer_offsets-37 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:00,972] INFO [Partition __consumer_offsets-37 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,973] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:00,973] INFO [Partition __consumer_offsets-37 broker=1001] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:00,993] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:00,994] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,001] INFO Created log for partition __consumer_offsets-18 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,003] INFO [Partition __consumer_offsets-18 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,004] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,004] INFO [Partition __consumer_offsets-18 broker=1001] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,014] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,018] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,020] INFO Created log for partition __consumer_offsets-34 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,022] INFO [Partition __consumer_offsets-34 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,022] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,031] INFO [Partition __consumer_offsets-34 broker=1001] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,048] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,050] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,052] INFO Created log for partition __consumer_offsets-15 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,061] INFO [Partition __consumer_offsets-15 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,061] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,062] INFO [Partition __consumer_offsets-15 broker=1001] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,087] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,095] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,099] INFO Created log for partition __consumer_offsets-12 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,099] INFO [Partition __consumer_offsets-12 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,100] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,105] INFO [Partition __consumer_offsets-12 broker=1001] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,116] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,120] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,121] INFO Created log for partition __consumer_offsets-31 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,122] INFO [Partition __consumer_offsets-31 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,122] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,122] INFO [Partition __consumer_offsets-31 broker=1001] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,149] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,150] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,151] INFO Created log for partition __consumer_offsets-9 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,152] INFO [Partition __consumer_offsets-9 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,152] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,153] INFO [Partition __consumer_offsets-9 broker=1001] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,174] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,185] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,190] INFO Created log for partition __consumer_offsets-47 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,191] INFO [Partition __consumer_offsets-47 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,191] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,192] INFO [Partition __consumer_offsets-47 broker=1001] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,202] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,204] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,211] INFO Created log for partition __consumer_offsets-19 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,212] INFO [Partition __consumer_offsets-19 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,215] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,216] INFO [Partition __consumer_offsets-19 broker=1001] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,234] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,242] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,250] INFO Created log for partition __consumer_offsets-28 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,250] INFO [Partition __consumer_offsets-28 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,251] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,251] INFO [Partition __consumer_offsets-28 broker=1001] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,262] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,267] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,269] INFO Created log for partition __consumer_offsets-38 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,286] INFO [Partition __consumer_offsets-38 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,287] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,292] INFO [Partition __consumer_offsets-38 broker=1001] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
zookeeper_1           | 2019-07-23 14:00:01,306 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /172.26.0.4:37094
zookeeper_1           | 2019-07-23 14:00:01,314 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@868] - Client attempting to establish new session at /172.26.0.4:37094
zookeeper_1           | 2019-07-23 14:00:01,317 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@617] - Established session 0x16c1f2182af0004 with negotiated timeout 30000 for client /172.26.0.4:37094
kafka_1               | [2019-07-23 14:00:01,352] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,353] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,356] INFO Created log for partition __consumer_offsets-35 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,374] INFO [Partition __consumer_offsets-35 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,376] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,383] INFO [Partition __consumer_offsets-35 broker=1001] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,402] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,403] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,405] INFO Created log for partition __consumer_offsets-44 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,407] INFO [Partition __consumer_offsets-44 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,407] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,408] INFO [Partition __consumer_offsets-44 broker=1001] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,477] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,477] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,478] INFO Created log for partition __consumer_offsets-6 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,479] INFO [Partition __consumer_offsets-6 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,480] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,483] INFO [Partition __consumer_offsets-6 broker=1001] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,500] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,501] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,502] INFO Created log for partition __consumer_offsets-25 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,503] INFO [Partition __consumer_offsets-25 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,503] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,503] INFO [Partition __consumer_offsets-25 broker=1001] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,535] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,537] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,539] INFO Created log for partition __consumer_offsets-16 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,540] INFO [Partition __consumer_offsets-16 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,541] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,541] INFO [Partition __consumer_offsets-16 broker=1001] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,549] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,550] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,551] INFO Created log for partition __consumer_offsets-22 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,551] INFO [Partition __consumer_offsets-22 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,552] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,552] INFO [Partition __consumer_offsets-22 broker=1001] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,567] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,569] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,572] INFO Created log for partition __consumer_offsets-41 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,574] INFO [Partition __consumer_offsets-41 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,574] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,575] INFO [Partition __consumer_offsets-41 broker=1001] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,596] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,603] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,605] INFO Created log for partition __consumer_offsets-32 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,605] INFO [Partition __consumer_offsets-32 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,605] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,606] INFO [Partition __consumer_offsets-32 broker=1001] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,620] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,623] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,629] INFO Created log for partition __consumer_offsets-3 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,637] INFO [Partition __consumer_offsets-3 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,637] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,637] INFO [Partition __consumer_offsets-3 broker=1001] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,663] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,664] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,667] INFO Created log for partition __consumer_offsets-13 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,677] INFO [Partition __consumer_offsets-13 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,677] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,678] INFO [Partition __consumer_offsets-13 broker=1001] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,692] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,693] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,694] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,695] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,696] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,696] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,697] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,698] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,698] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,704] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,712] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,713] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,714] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,714] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,715] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,715] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,716] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,717] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,718] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,719] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,720] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,720] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,721] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,722] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,722] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,723] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,724] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,725] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,726] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,726] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,727] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,728] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,729] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,729] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,730] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,731] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,732] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,732] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,732] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,733] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,733] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,733] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,733] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,733] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,734] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,734] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,734] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,734] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,734] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,735] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
zookeeper_1           | 2019-07-23 14:00:01,748 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@494] - Processed session termination for sessionid: 0x16c1f2182af0002
zookeeper_1           | 2019-07-23 14:00:01,753 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1007] - Closed socket connection for client /172.26.0.4:37090 which had sessionid 0x16c1f2182af0002
kafka_1               | [2019-07-23 14:00:01,768] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-22 in 75 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,807] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions Set(prefixes-0) (kafka.server.ReplicaFetcherManager)
kafka_1               | [2019-07-23 14:00:01,812] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,813] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,813] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,814] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,815] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,815] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,816] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,817] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,818] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,819] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,820] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,820] INFO [Log partition=prefixes-0, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,820] INFO [Log partition=prefixes-0, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:01,821] INFO Created log for partition prefixes-0 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:01,822] INFO [Partition prefixes-0 broker=1001] No checkpointed highwatermark is found for partition prefixes-0 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,822] INFO Replica loaded for partition prefixes-0 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:01,822] INFO [Partition prefixes-0 broker=1001] prefixes-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:01,825] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-47 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,827] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,828] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,828] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,830] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
zookeeper_1           | 2019-07-23 14:00:01,831 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x16c1f2182af0001 type:setData cxid:0x4 zxid:0x9e txntype:-1 reqpath:n/a Error Path:/config/topics/predictions Error:KeeperErrorCode = NoNode for /config/topics/predictions
kafka_1               | [2019-07-23 14:00:01,833] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,834] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,838] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,842] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,845] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,845] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,846] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,849] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,850] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,851] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,852] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,853] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,854] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,856] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,857] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,857] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,858] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,860] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-3 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,862] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-6 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,863] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,865] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,866] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,866] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,867] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
apromore_1            | [2019-07-23 14:00:01.864] start-signalling-1           <DE0005I> Started bundle 'org.eclipse.gemini.blueprint.extender' version '1.0.2.RELEASE'. 
apromore_1            | [2019-07-23 14:00:01.867] system-artifacts             <DE0004I> Starting bundle 'org.eclipse.gemini.blueprint.io' version '1.0.2.RELEASE'. 
kafka_1               | [2019-07-23 14:00:01,868] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,868] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,869] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,870] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,871] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,874] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,874] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,874] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
kafka_1               | [2019-07-23 14:00:01,874] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
apromore_1            | [2019-07-23 14:00:01.878] start-signalling-1           <DE0005I> Started bundle 'org.eclipse.gemini.blueprint.io' version '1.0.2.RELEASE'. 
apromore_1            | [2019-07-23 14:00:01.889] system-artifacts             <DE0004I> Starting bundle 'org.eclipse.virgo.kernel.agent.dm' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:01.892] start-signalling-1           <DE0005I> Started bundle 'org.eclipse.virgo.kernel.agent.dm' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:01.897] system-artifacts             <DE0004I> Starting bundle 'org.eclipse.virgo.kernel.deployer.dm' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:01.918] system-artifacts             <DE0004I> Starting bundle 'org.eclipse.equinox.ds' version '1.4.0.v20120112-1400'. 
kafka_1               | Created topic "predictions".
kafka_1               | [2019-07-23 14:00:01,994] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions Set(predictions-0) (kafka.server.ReplicaFetcherManager)
zookeeper_1           | 2019-07-23 14:00:02,000 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@494] - Processed session termination for sessionid: 0x16c1f2182af0001
zookeeper_1           | 2019-07-23 14:00:02,002 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@494] - Processed session termination for sessionid: 0x16c1f2182af0003
kafka_1               | [2019-07-23 14:00:02,003] INFO [Log partition=predictions-0, dir=/kafka/kafka-logs-5803ed067b11] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1               | [2019-07-23 14:00:02,004] INFO [Log partition=predictions-0, dir=/kafka/kafka-logs-5803ed067b11] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
zookeeper_1           | 2019-07-23 14:00:02,003 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1007] - Closed socket connection for client /172.26.0.4:37088 which had sessionid 0x16c1f2182af0001
zookeeper_1           | 2019-07-23 14:00:02,005 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1007] - Closed socket connection for client /172.26.0.4:37092 which had sessionid 0x16c1f2182af0003
kafka_1               | [2019-07-23 14:00:02,008] INFO Created log for partition predictions-0 in /kafka/kafka-logs-5803ed067b11 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
kafka_1               | [2019-07-23 14:00:02,008] INFO [Partition predictions-0 broker=1001] No checkpointed highwatermark is found for partition predictions-0 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:02,008] INFO Replica loaded for partition predictions-0 with initial high watermark 0 (kafka.cluster.Replica)
kafka_1               | [2019-07-23 14:00:02,009] INFO [Partition predictions-0 broker=1001] predictions-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
kafka_1               | [2019-07-23 14:00:02,162] INFO [GroupCoordinator 1001]: Preparing to rebalance group predict in state PreparingRebalance with old generation 0 (__consumer_offsets-7) (reason: Adding new member kafka-python-1.4.6-b679a36f-fc59-4758-a6e0-615f162aa250) (kafka.coordinator.group.GroupCoordinator)
apromore_1            | [2019-07-23 14:00:02.172] start-signalling-1           <DE0005I> Started bundle 'org.eclipse.equinox.ds' version '1.4.0.v20120112-1400'. 
apromore_1            | [2019-07-23 14:00:02.174] system-artifacts             <DE0004I> Starting bundle 'org.eclipse.equinox.util' version '1.0.300.v20111010-1614'. 
apromore_1            | [2019-07-23 14:00:02.219] start-signalling-1           <DE0005I> Started bundle 'org.eclipse.equinox.util' version '1.0.300.v20111010-1614'. 
apromore_1            | [2019-07-23 14:00:02.221] system-artifacts             <DE0004I> Starting configuration 'osgi.console' version '0.0.0'. 
zookeeper_1           | 2019-07-23 14:00:02,226 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@494] - Processed session termination for sessionid: 0x16c1f2182af0004
zookeeper_1           | 2019-07-23 14:00:02,229 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1007] - Closed socket connection for client /172.26.0.4:37094 which had sessionid 0x16c1f2182af0004
kafka_1               | [2019-07-23 14:00:02,238] INFO [GroupCoordinator 1001]: Stabilized group predict generation 1 (__consumer_offsets-7) (kafka.coordinator.group.GroupCoordinator)
apromore_1            | [2019-07-23 14:00:02.253] system-artifacts             <DE0005I> Started configuration 'osgi.console' version '0.0.0'. 
kafka_1               | [2019-07-23 14:00:02,256] INFO [GroupCoordinator 1001]: Assignment received from leader for group predict for generation 1 (kafka.coordinator.group.GroupCoordinator)
kafka_1               | [2019-07-23 14:00:02,361] INFO [GroupCoordinator 1001]: Preparing to rebalance group predict in state PreparingRebalance with old generation 1 (__consumer_offsets-7) (reason: Updating metadata for member kafka-python-1.4.6-b679a36f-fc59-4758-a6e0-615f162aa250) (kafka.coordinator.group.GroupCoordinator)
kafka_1               | [2019-07-23 14:00:02,363] INFO [GroupCoordinator 1001]: Stabilized group predict generation 2 (__consumer_offsets-7) (kafka.coordinator.group.GroupCoordinator)
kafka_1               | [2019-07-23 14:00:02,367] INFO [GroupCoordinator 1001]: Assignment received from leader for group predict for generation 2 (kafka.coordinator.group.GroupCoordinator)
apromore_1            | [2019-07-23 14:00:02.390] start-signalling-1           <DE0005I> Started bundle 'org.eclipse.virgo.kernel.deployer.dm' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:02.391] start-signalling-1           <DE0005I> Started plan 'org.eclipse.virgo.kernel.userregion.blueprint' version '3.6.4'. 
apromore_1            | [2019-07-23 14:00:02.550] system-artifacts             <DE0000I> Installing plan 'org.eclipse.virgo.web.tomcat' version '3.6.4'. 
apromore_1            | [2019-07-23 14:00:02.554] system-artifacts             <DE0000I> Installing configuration 'org.eclipse.virgo.web' version '0.0.0'. 
apromore_1            | [2019-07-23 14:00:02.559] system-artifacts             <DE0000I> Installing bundle 'org.eclipse.virgo.web.spring.integration' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:02.577] system-artifacts             <DE0000I> Installing bundle 'org.eclipse.gemini.web.core' version '2.2.7.RELEASE'. 
apromore_1            | [2019-07-23 14:00:02.604] system-artifacts             <DE0000I> Installing bundle 'org.eclipse.gemini.web.tomcat' version '2.2.7.RELEASE'. 
apromore_1            | [2019-07-23 14:00:02.618] system-artifacts             <DE0000I> Installing bundle 'org.eclipse.virgo.web.core' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:02.628] system-artifacts             <DE0000I> Installing bundle 'org.eclipse.virgo.web.dm' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:02.637] system-artifacts             <DE0000I> Installing bundle 'org.eclipse.virgo.web.tomcat.support' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:02.643] system-artifacts             <DE0000I> Installing bundle 'org.eclipse.virgo.web.servlet.adapter' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:03.816] system-artifacts             <DE0001I> Installed configuration 'org.eclipse.virgo.web' version '0.0.0'. 
apromore_1            | [2019-07-23 14:00:03.817] system-artifacts             <DE0001I> Installed bundle 'org.eclipse.virgo.web.spring.integration' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:03.818] system-artifacts             <DE0001I> Installed bundle 'org.eclipse.gemini.web.core' version '2.2.7.RELEASE'. 
apromore_1            | [2019-07-23 14:00:03.819] system-artifacts             <DE0001I> Installed bundle 'org.eclipse.gemini.web.tomcat' version '2.2.7.RELEASE'. 
apromore_1            | [2019-07-23 14:00:03.820] system-artifacts             <DE0001I> Installed bundle 'org.eclipse.virgo.web.core' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:03.820] system-artifacts             <DE0001I> Installed bundle 'org.eclipse.virgo.web.dm' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:03.821] system-artifacts             <DE0001I> Installed bundle 'org.eclipse.virgo.web.tomcat.support' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:03.822] system-artifacts             <DE0001I> Installed bundle 'org.eclipse.virgo.web.servlet.adapter' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:03.823] system-artifacts             <DE0001I> Installed plan 'org.eclipse.virgo.web.tomcat' version '3.6.4'. 
apromore_1            | [2019-07-23 14:00:03.833] system-artifacts             <DE0004I> Starting plan 'org.eclipse.virgo.web.tomcat' version '3.6.4'. 
apromore_1            | [2019-07-23 14:00:03.834] system-artifacts             <DE0004I> Starting configuration 'org.eclipse.virgo.web' version '0.0.0'. 
apromore_1            | [2019-07-23 14:00:03.844] system-artifacts             <DE0005I> Started configuration 'org.eclipse.virgo.web' version '0.0.0'. 
apromore_1            | [2019-07-23 14:00:03.846] system-artifacts             <DE0005I> Started bundle 'org.eclipse.virgo.web.spring.integration' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:03.848] system-artifacts             <DE0004I> Starting bundle 'org.eclipse.gemini.web.core' version '2.2.7.RELEASE'. 
apromore_1            | [2019-07-23 14:00:03.861] start-signalling-1           <DE0005I> Started bundle 'org.eclipse.gemini.web.core' version '2.2.7.RELEASE'. 
apromore_1            | [2019-07-23 14:00:03.862] system-artifacts             <DE0004I> Starting bundle 'org.eclipse.gemini.web.tomcat' version '2.2.7.RELEASE'. 
apromore_1            | [2019-07-23 14:00:04.256] system-artifacts             <TC0000I> Starting Tomcat. 
apromore_1            | [2019-07-23 14:00:04.289] system-artifacts             <TC0010I> Creating HTTP/1.1 connector with scheme http on port 9000. 
apromore_1            | [2019-07-23 14:00:04.296] system-artifacts             <TC0010I> Creating HTTP/1.1 connector with scheme https on port 8443. 
apromore_1            | [2019-07-23 14:00:04.298] system-artifacts             <TC0010I> Creating AJP/1.3 connector with scheme http on port 8009. 
apromore_1            | [2019-07-23 14:00:04.304] system-artifacts             <TC0001I> Started Tomcat. 
apromore_1            | [2019-07-23 14:00:04.313] system-artifacts             <DE0004I> Starting bundle 'org.eclipse.virgo.web.core' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:04.334] system-artifacts             <DE0004I> Starting bundle 'org.eclipse.virgo.web.dm' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:04.342] start-signalling-1           <DE0005I> Started bundle 'org.eclipse.virgo.web.dm' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:04.349] system-artifacts             <DE0005I> Started bundle 'org.eclipse.virgo.web.tomcat.support' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:04.357] system-artifacts             <DE0004I> Starting bundle 'org.eclipse.virgo.web.servlet.adapter' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:04.363] start-signalling-1           <DE0005I> Started bundle 'org.eclipse.virgo.web.servlet.adapter' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:04.489] region-dm-6                  <WE0006W> WABHeaders set to 'defaulted' in org.eclipse.virgo.web.properties. This option may not be supported in future releases. 
apromore_1            | [2019-07-23 14:00:04.490] start-signalling-1           <DE0005I> Started bundle 'org.eclipse.gemini.web.tomcat' version '2.2.7.RELEASE'. 
apromore_1            | [2019-07-23 14:00:04.518] start-signalling-1           <DE0005I> Started bundle 'org.eclipse.virgo.web.core' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:04.522] start-signalling-1           <DE0005I> Started plan 'org.eclipse.virgo.web.tomcat' version '3.6.4'. 
apromore_1            | [2019-07-23 14:00:04.590] system-artifacts             <DE0000I> Installing configuration 'org.eclipse.virgo.apps.repository' version '0.0.0'. 
apromore_1            | [2019-07-23 14:00:04.603] system-artifacts             <DE0001I> Installed configuration 'org.eclipse.virgo.apps.repository' version '0.0.0'. 
apromore_1            | [2019-07-23 14:00:04.608] system-artifacts             <DE0004I> Starting configuration 'org.eclipse.virgo.apps.repository' version '0.0.0'. 
apromore_1            | [2019-07-23 14:00:04.619] system-artifacts             <DE0005I> Started configuration 'org.eclipse.virgo.apps.repository' version '0.0.0'. 
apromore_1            | [2019-07-23 14:00:04.691] system-artifacts             <DE0000I> Installing plan 'org.eclipse.virgo.management' version '3.6.4'. 
apromore_1            | [2019-07-23 14:00:04.741] system-artifacts             <DE0000I> Installing bundle 'osgi.enterprise' version '4.2.0.v201108120515'. 
apromore_1            | [2019-07-23 14:00:04.758] system-artifacts             <DE0000I> Installing bundle 'org.eclipse.gemini.management' version '1.0.5.RELEASE'. 
apromore_1            | [2019-07-23 14:00:04.763] system-artifacts             <DE0000I> Installing bundle 'org.eclipse.virgo.management.fragment' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:04.850] system-artifacts             <DE0001I> Installed bundle 'osgi.enterprise' version '4.2.0.v201108120515'. 
apromore_1            | [2019-07-23 14:00:04.852] system-artifacts             <DE0001I> Installed bundle 'org.eclipse.gemini.management' version '1.0.5.RELEASE'. 
apromore_1            | [2019-07-23 14:00:04.853] system-artifacts             <DE0001I> Installed bundle 'org.eclipse.virgo.management.fragment' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:04.855] system-artifacts             <DE0001I> Installed plan 'org.eclipse.virgo.management' version '3.6.4'. 
apromore_1            | [2019-07-23 14:00:04.866] system-artifacts             <DE0004I> Starting plan 'org.eclipse.virgo.management' version '3.6.4'. 
apromore_1            | [2019-07-23 14:00:04.868] system-artifacts             <DE0004I> Starting bundle 'osgi.enterprise' version '4.2.0.v201108120515'. 
apromore_1            | [2019-07-23 14:00:04.888] start-signalling-1           <DE0005I> Started bundle 'osgi.enterprise' version '4.2.0.v201108120515'. 
apromore_1            | [2019-07-23 14:00:04.890] system-artifacts             <DE0004I> Starting bundle 'org.eclipse.gemini.management' version '1.0.5.RELEASE'. 
apromore_1            | [2019-07-23 14:00:04.902] start-signalling-1           <DE0005I> Started bundle 'org.eclipse.gemini.management' version '1.0.5.RELEASE'. 
apromore_1            | [2019-07-23 14:00:04.904] system-artifacts             <DE0005I> Started bundle 'org.eclipse.virgo.management.fragment' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:04.905] system-artifacts             <DE0005I> Started plan 'org.eclipse.virgo.management' version '3.6.4'. 
apromore_1            | [2019-07-23 14:00:04.907] sync Event Dispatcher Thread <UR0001I> User region ready. 
apromore_1            | [2019-07-23 14:00:04.925] startup-readiness            <KE0007I> Virgo ready. Started for 16.996s. 
apromore_1            | [2019-07-23 14:00:05.931] fs-watcher                   <HD0001I> Hot deployer processing 'INITIAL' event for file 'org.eclipse.virgo.apps.repository_3.6.4.RELEASE.par'. 
apromore_1            | [2019-07-23 14:00:06.096] fs-watcher                   <DE0000I> Installing par 'org.eclipse.virgo.apps.repository' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:06.098] fs-watcher                   <DE0000I> Installing bundle 'org.eclipse.virgo.apps.repository-3.6.4.RELEASE-org.eclipse.virgo.apps.repository.core' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:06.100] fs-watcher                   <DE0000I> Installing bundle 'org.eclipse.virgo.apps.repository-3.6.4.RELEASE-org.eclipse.virgo.apps.repository.web' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:07.762] fs-watcher                   <DE0001I> Installed bundle 'org.eclipse.virgo.apps.repository-3.6.4.RELEASE-org.eclipse.virgo.apps.repository.core' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:07.763] fs-watcher                   <DE0001I> Installed bundle 'org.eclipse.virgo.apps.repository-3.6.4.RELEASE-org.eclipse.virgo.apps.repository.web' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:07.764] fs-watcher                   <DE0001I> Installed bundle 'org.eclipse.virgo.apps.repository-3.6.4.RELEASE-synthetic.context' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:07.765] fs-watcher                   <DE0001I> Installed par 'org.eclipse.virgo.apps.repository' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:07.771] fs-watcher                   <DE0004I> Starting par 'org.eclipse.virgo.apps.repository' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:07.772] fs-watcher                   <DE0004I> Starting bundle 'org.eclipse.virgo.apps.repository-3.6.4.RELEASE-org.eclipse.virgo.apps.repository.core' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:07.819] fs-watcher                   <DE0004I> Starting bundle 'org.eclipse.virgo.apps.repository-3.6.4.RELEASE-org.eclipse.virgo.apps.repository.web' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:07.822] fs-watcher                   <DE0004I> Starting bundle 'org.eclipse.virgo.apps.repository-3.6.4.RELEASE-synthetic.context' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:07.822] start-signalling-1           <WE0000I> Starting web bundle 'org.eclipse.virgo.apps.repository-3.6.4.RELEASE-org.eclipse.virgo.apps.repository.web' version '3.6.4.RELEASE' with context path '/org.eclipse.virgo.apps.repository'. 
apromore_1            | [2019-07-23 14:00:07.829] start-signalling-2           <DE0005I> Started bundle 'org.eclipse.virgo.apps.repository-3.6.4.RELEASE-synthetic.context' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:07.829] fs-watcher                   <HD0001I> Hot deployer processing 'INITIAL' event for file 'org.eclipse.virgo.management.console_3.6.4.RELEASE.jar'. 
apromore_1            | [2019-07-23 14:00:07.923] fs-watcher                   <DE0000I> Installing bundle 'org.eclipse.virgo.management.console' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:08.000] start-signalling-2           <DE0005I> Started bundle 'org.eclipse.virgo.apps.repository-3.6.4.RELEASE-org.eclipse.virgo.apps.repository.core' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:08.175] fs-watcher                   <DE0001I> Installed bundle 'org.eclipse.virgo.management.console' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:08.181] fs-watcher                   <DE0004I> Starting bundle 'org.eclipse.virgo.management.console' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:08.186] start-signalling-2           <WE0000I> Starting web bundle 'org.eclipse.virgo.management.console' version '3.6.4.RELEASE' with context path '/admin'. 
apromore_1            | [2019-07-23 14:00:08.186] fs-watcher                   <HD0001I> Hot deployer processing 'INITIAL' event for file 'apromore-root.plan'. 
apromore_1            | [2019-07-23 14:00:08.264] fs-watcher                   <DE0000I> Installing plan 'org.apromore.root' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.271] fs-watcher                   <DE0000I> Installing plan 'org.apromore.manager' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.289] fs-watcher                   <DE0000I> Installing plan 'org.apromore.portal' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.305] fs-watcher                   <DE0000I> Installing plan 'org.apromore.filestore' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.314] fs-watcher                   <DE0000I> Installing plan 'org.apromore.editor' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:08.325] fs-watcher                   <DE0000I> Installing plan 'org.apromore.bpmn-editor' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.332] fs-watcher                   <DE0000I> Installing plan 'org.apromore.csvimporter' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:08.348] fs-watcher                   <DE0000I> Installing plan 'org.apromore.plugin.canonisers' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.358] fs-watcher                   <DE0000I> Installing plan 'org.apromore.plugin.bimp-simulator' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:08.366] fs-watcher                   <DE0000I> Installing plan 'org.apromore.plugin.compare' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.385] fs-watcher                   <DE0000I> Installing plan 'org.apromore.plugin.log-animation' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:08.393] fs-watcher                   <DE0000I> Installing plan 'org.apromore.plugin.log-visualizer' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.401] fs-watcher                   <DE0000I> Installing plan 'org.apromore.plugin.prodrift' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.408] fs-watcher                   <DE0000I> Installing plan 'org.apromore.plugin.process-discoverer' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:08.415] fs-watcher                   <DE0000I> Installing plan 'org.apromore.plugin.stagemining' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.427] fs-watcher                   <DE0000I> Installing plan 'org.apromore.plugin.predictive-monitor' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:08.434] fs-watcher                   <DE0000I> Installing plan 'org.apromore.plugin.predictor-training' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:08.447] fs-watcher                   <DE0000I> Installing plan 'org.apromore.plugin.perfmining' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:08.455] fs-watcher                   <DE0000I> Installing plan 'org.apromore.plugin.similaritysearch' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.463] fs-watcher                   <DE0000I> Installing plan 'org.apromore.plugin.merge' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.483] fs-watcher                   <DE0000I> Installing plan 'org.apromore.plugin.metrics' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.488] fs-watcher                   <DE0000I> Installing configuration 'site' version '0.0.0'. 
apromore_1            | [2019-07-23 14:00:08.491] fs-watcher                   <DE0000I> Installing configuration 'git' version '0.0.0'. 
apromore_1            | [2019-07-23 14:00:08.496] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.database-h2' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.501] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.database-mysql' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.512] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.anf-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.540] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.aris-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.588] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.bpmn-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.604] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.cpf-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.618] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.epml-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.641] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.pnml-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.647] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.rlf-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.693] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.xpdl-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.716] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.yawl-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.721] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.api-provider' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.731] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.annotation-api-provider' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.736] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.canoniser-api-provider' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.742] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.deployment-api-provider' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.755] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.graph' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.764] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.manager-security' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.833] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.manager' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.842] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.manager-ws' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.882] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.manager-ws-model' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.887] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.manager-client' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.891] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.portal-plugin-api' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:08.898] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.portal-custom-gui' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:09.110] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.portal' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:09.131] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.filestore-client' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:09.168] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.filestore' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:09.182] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.editor-platform-extension-diagram' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:09.300] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.editor-platform-extension-bpmn2_0' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:09.304] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.editor-platform-extension-downloader' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:09.344] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.editor-platform-extension-epc' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:09.356] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.editor-platform-extension-jpdl' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:10.368] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.editor-platform-extension-pdf' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:10.375] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.editor-platform-extension-petrinet' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:10.382] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.editor-platform-extension-syntaxchecker' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:10.434] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.editor-platform-extension-xpdl' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:10.549] start-signalling-2           <WE0001I> Started web bundle 'org.eclipse.virgo.management.console' version '3.6.4.RELEASE' with context path '/admin'. 
apromore_1            | [2019-07-23 14:00:10.550] start-signalling-2           <DE0005I> Started bundle 'org.eclipse.virgo.management.console' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:11.801] start-signalling-1           <WE0001I> Started web bundle 'org.eclipse.virgo.apps.repository-3.6.4.RELEASE-org.eclipse.virgo.apps.repository.web' version '3.6.4.RELEASE' with context path '/org.eclipse.virgo.apps.repository'. 
apromore_1            | [2019-07-23 14:00:11.802] start-signalling-1           <DE0005I> Started bundle 'org.eclipse.virgo.apps.repository-3.6.4.RELEASE-org.eclipse.virgo.apps.repository.web' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:11.803] start-signalling-1           <DE0005I> Started par 'org.eclipse.virgo.apps.repository' version '3.6.4.RELEASE'. 
apromore_1            | [2019-07-23 14:00:11.831] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.editor-platform-extension-yawl' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:12.576] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.editor' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:12.715] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.apromore-bpmneditor' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:12.720] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.csvimporter-portal' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:12.727] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.csvimporter-logic' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:12.732] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.canoniser-aris' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:12.760] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.canoniser-bpmn' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:12.766] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.canoniser-epml' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:12.791] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.canoniser-pnml' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:12.808] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.canoniser-xpdl' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:12.831] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.canoniser-yawl' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:12.838] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.bimp-editor-plugin' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:12.845] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.bimp-editor-plugin2' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:12.849] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.bimp-portal-plugin' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:12.854] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.compare-logic' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:12.866] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.compareBP-portal-plugin' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:12.879] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.compareBP-portal-plugin2' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:13.007] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.log-animation-logic' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:13.025] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.log-animation-portal-plugin' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:13.045] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.log-animation-portal-plugin2' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:13.052] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.log-visualizer-logic' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:13.059] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.log-visualizer-logic-ws' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:13.143] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.prodrift-osgi' version '2.5.0'. 
apromore_1            | [2019-07-23 14:00:13.146] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.prodrift-logic' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:13.156] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.prodrift-portal-plugin' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:13.212] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.process-discoverer' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:13.237] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.stagemining-logic' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:13.249] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.stagemining-portal-plugin' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:13.257] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.predictive-monitor-logic' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:13.267] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.predictive-monitor-portal-plugin' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:13.378] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.predictor-training-portal-plugin' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:13.388] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.perfmining-logic' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:13.433] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.perfmining-portal-plugin' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:13.449] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.similaritysearch-osgi' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:13.455] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.similaritysearch-logic' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:13.466] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.similaritysearch-portal' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:13.472] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.merge-logic' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:13.480] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.merge-portal' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:13.485] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.metrics-logic' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:13.490] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.metrics-portal-plugin' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:13.497] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.metrics-editor-plugin' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:13.504] fs-watcher                   <DE0000I> Installing bundle 'org.apromore.plugin.metrics-editor-plugin2' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:30.204] fs-watcher                   <ME0002W> Dump contributor 'heap' failed during contribution to dump '1563890430180' org.eclipse.virgo.medic.dump.DumpContributionFailedException: Failed to generate heap dump contribution
apromore_1            | 	at org.eclipse.virgo.medic.dump.impl.heap.HeapDumpContributor.contribute(HeapDumpContributor.java:90)
apromore_1            | 	at org.eclipse.virgo.medic.dump.impl.StandardDumpGenerator.generateDump(StandardDumpGenerator.java:67)
apromore_1            | 	at org.eclipse.virgo.kernel.userregion.internal.quasi.DependencyCalculator.generateDump(DependencyCalculator.java:423)
apromore_1            | 	at org.eclipse.virgo.kernel.userregion.internal.quasi.DependencyCalculator.calculateDependencies(DependencyCalculator.java:138)
apromore_1            | 	at org.eclipse.virgo.kernel.userregion.internal.quasi.StandardQuasiFramework.getDependencies(StandardQuasiFramework.java:249)
apromore_1            | 	at org.eclipse.virgo.kernel.userregion.internal.quasi.StandardQuasiFramework.resolve(StandardQuasiFramework.java:223)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.stage.resolve.internal.QuasiResolveStage.process(QuasiResolveStage.java:43)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.internal.StandardPipeline.doProcessGraph(StandardPipeline.java:62)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.internal.CompensatingPipeline.doProcessGraph(CompensatingPipeline.java:73)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.stage.AbstractPipelineStage.process(AbstractPipelineStage.java:41)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.internal.StandardPipeline.doProcessGraph(StandardPipeline.java:62)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.stage.AbstractPipelineStage.process(AbstractPipelineStage.java:41)
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.driveInstallPipeline(PipelinedApplicationDeployer.java:359)
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.doInstall(PipelinedApplicationDeployer.java:185)
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.install(PipelinedApplicationDeployer.java:140)
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.deploy(PipelinedApplicationDeployer.java:253)
apromore_1            | 	at org.eclipse.virgo.nano.deployer.hot.HotDeploymentFileSystemListener.deploy(HotDeployerFileSystemListener.java:225)
apromore_1            | 	at org.eclipse.virgo.nano.deployer.hot.HotDeploymentFileSystemListener.deployIfNotDeployed(HotDeployerFileSystemListener.java:237)
apromore_1            | 	at org.eclipse.virgo.nano.deployer.hot.HotDeploymentFileSystemListener.onChange(HotDeployerFileSystemListener.java:88)
apromore_1            | 	at org.eclipse.virgo.util.io.FileSystemChecker.notifyListeners(FileSystemChecker.java:380)
apromore_1            | 	at org.eclipse.virgo.util.io.FileSystemChecker.check(FileSystemChecker.java:289)
apromore_1            | 	at org.eclipse.virgo.nano.deployer.hot.WatchTask.run(WatchTask.java:49)
apromore_1            | 	at java.lang.Thread.run(Thread.java:748)
apromore_1            | Caused by: java.lang.reflect.InvocationTargetException: null
apromore_1            | 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
apromore_1            | 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
apromore_1            | 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
apromore_1            | 	at java.lang.reflect.Method.invoke(Method.java:498)
apromore_1            | 	at org.eclipse.virgo.medic.dump.impl.heap.HeapDumpContributor.contribute(HeapDumpContributor.java:77)
apromore_1            | 	... 22 common frames omitted
apromore_1            | Caused by: java.lang.IllegalArgumentException: heapdump file must have .hprof extention
apromore_1            | 	at sun.management.HotSpotDiagnostic.dumpHeap(HotSpotDiagnostic.java:51)
apromore_1            | 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
apromore_1            | 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
apromore_1            | 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
apromore_1            | 	at java.lang.reflect.Method.invoke(Method.java:498)
apromore_1            | 	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
apromore_1            | 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
apromore_1            | 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
apromore_1            | 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
apromore_1            | 	at java.lang.reflect.Method.invoke(Method.java:498)
apromore_1            | 	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
apromore_1            | 	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
apromore_1            | 	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
apromore_1            | 	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
apromore_1            | 	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
apromore_1            | 	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
apromore_1            | 	at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:138)
apromore_1            | 	at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:252)
apromore_1            | 	at javax.management.StandardMBean.invoke(StandardMBean.java:405)
apromore_1            | 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:819)
apromore_1            | 	at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:801)
apromore_1            | 	at com.sun.jmx.mbeanserver.MXBeanProxy$InvokeHandler.invoke(MXBeanProxy.java:150)
apromore_1            | 	at com.sun.jmx.mbeanserver.MXBeanProxy.invoke(MXBeanProxy.java:167)
apromore_1            | 	at javax.management.MBeanServerInvocationHandler.invoke(MBeanServerInvocationHandler.java:258)
apromore_1            | 	at com.sun.proxy.$Proxy4.dumpHeap(Unknown Source)
apromore_1            | 	... 27 common frames omitted
apromore_1            | 
apromore_1            | [2019-07-23 14:00:39.071] fs-watcher                   <ME0003I> Dump 'serviceability/dump/2019-07-23-14-00-180' generated 
apromore_1            | [2019-07-23 14:00:39.083] fs-watcher                   <DE0002E> Installation of plan 'org.apromore.root' version '1.1.0' failed. org.eclipse.virgo.kernel.osgi.framework.UnableToSatisfyBundleDependenciesException: Unable to satisfy dependencies of bundle 'org.apromore.plugin.compareBP-portal-plugin' at version '1.1.0': Cannot resolve: org.apromore.plugin.compareBP-portal-plugin
apromore_1            |     Resolver report:
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.compareBP-portal-plugin_1.1.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.apache.xml.resolver; version="0.0.0">. Caused by missing constraint in bundle <com.sun.xml.bind.extra_2.2.7>
apromore_1            |              constraint: <Import-Package: org.apache.xml.resolver; version="0.0.0">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: com.sun.xml.bind.serializer; version="[2.2.0,2.2.0]">. Caused by missing constraint in bundle <com.springsource.com.sun.tools.xjc_2.2.0>
apromore_1            |              constraint: <Import-Package: com.sun.xml.bind.serializer; version="[2.2.0,2.2.0]">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.log-animation-portal-plugin2_1.0.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.compareBP-portal-plugin2_1.1.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.model; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.log-animation-portal-plugin_1.0.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.model; version="[2.16.0,3.0.0)">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.extension.std; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.process-discoverer_1.0.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.extension.std; version="[2.16.0,3.0.0)">
apromore_1            | 
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.stage.resolve.internal.QuasiResolveStage.process(QuasiResolveStage.java:46)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.internal.StandardPipeline.doProcessGraph(StandardPipeline.java:62)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.internal.CompensatingPipeline.doProcessGraph(CompensatingPipeline.java:73)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.stage.AbstractPipelineStage.process(AbstractPipelineStage.java:41)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.internal.StandardPipeline.doProcessGraph(StandardPipeline.java:62)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.stage.AbstractPipelineStage.process(AbstractPipelineStage.java:41)
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.driveInstallPipeline(PipelinedApplicationDeployer.java:359)
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.doInstall(PipelinedApplicationDeployer.java:185)
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.install(PipelinedApplicationDeployer.java:140)
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.deploy(PipelinedApplicationDeployer.java:253)
apromore_1            | 	at org.eclipse.virgo.nano.deployer.hot.HotDeploymentFileSystemListener.deploy(HotDeployerFileSystemListener.java:225)
apromore_1            | 	at org.eclipse.virgo.nano.deployer.hot.HotDeploymentFileSystemListener.deployIfNotDeployed(HotDeployerFileSystemListener.java:237)
apromore_1            | 	at org.eclipse.virgo.nano.deployer.hot.HotDeploymentFileSystemListener.onChange(HotDeployerFileSystemListener.java:88)
apromore_1            | 	at org.eclipse.virgo.util.io.FileSystemChecker.notifyListeners(FileSystemChecker.java:380)
apromore_1            | 	at org.eclipse.virgo.util.io.FileSystemChecker.check(FileSystemChecker.java:289)
apromore_1            | 	at org.eclipse.virgo.nano.deployer.hot.WatchTask.run(WatchTask.java:49)
apromore_1            | 	at java.lang.Thread.run(Thread.java:748)
apromore_1            | 
apromore_1            | [2019-07-23 14:00:39.086] fs-watcher                   <DE0003E> Install failed for configuration 'site' version '0.0.0'. 
apromore_1            | [2019-07-23 14:00:39.087] fs-watcher                   <DE0003E> Install failed for configuration 'git' version '0.0.0'. 
apromore_1            | [2019-07-23 14:00:39.087] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.database-h2' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.088] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.database-mysql' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.089] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.anf-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.090] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.aris-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.091] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.bpmn-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.091] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.cpf-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.092] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.epml-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.093] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.pnml-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.094] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.rlf-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.095] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.xpdl-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.096] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.yawl-schema' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.096] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.api-provider' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.097] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.annotation-api-provider' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.098] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.canoniser-api-provider' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.098] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.deployment-api-provider' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.099] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.graph' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.101] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.manager-security' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.102] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.manager' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.103] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.manager-ws' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.105] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.manager' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.107] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.manager-ws-model' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.109] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.manager-client' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.111] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.portal-plugin-api' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.112] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.portal-custom-gui' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.113] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.portal' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.114] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.portal' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.115] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.filestore-client' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.116] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.filestore' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.117] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.filestore' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.118] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.editor-platform-extension-diagram' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:39.119] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.editor-platform-extension-bpmn2_0' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:39.120] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.editor-platform-extension-downloader' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:39.121] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.editor-platform-extension-epc' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:39.121] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.editor-platform-extension-jpdl' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:39.122] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.editor-platform-extension-pdf' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:39.123] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.editor-platform-extension-petrinet' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:39.123] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.editor-platform-extension-syntaxchecker' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:39.125] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.editor-platform-extension-xpdl' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:39.126] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.editor-platform-extension-yawl' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:39.126] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.editor' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:39.127] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.editor' version '1.2.0'. 
apromore_1            | [2019-07-23 14:00:39.128] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.apromore-bpmneditor' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.129] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.bpmn-editor' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.131] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.csvimporter-portal' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.132] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.csvimporter-logic' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.133] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.csvimporter' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.134] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.canoniser-aris' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.135] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.canoniser-bpmn' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.136] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.canoniser-epml' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.137] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.canoniser-pnml' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.138] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.canoniser-xpdl' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.139] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.canoniser-yawl' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.140] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.plugin.canonisers' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.141] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.bimp-editor-plugin' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.142] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.bimp-editor-plugin2' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.143] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.bimp-portal-plugin' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.144] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.plugin.bimp-simulator' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.144] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.compare-logic' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.145] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.compareBP-portal-plugin' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.146] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.compareBP-portal-plugin2' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.147] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.plugin.compare' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.148] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.log-animation-logic' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.149] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.log-animation-portal-plugin' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.150] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.log-animation-portal-plugin2' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.151] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.plugin.log-animation' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.152] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.log-visualizer-logic' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.153] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.log-visualizer-logic-ws' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.154] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.plugin.log-visualizer' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.155] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.prodrift-osgi' version '2.5.0'. 
apromore_1            | [2019-07-23 14:00:39.156] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.prodrift-logic' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.156] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.prodrift-portal-plugin' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.157] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.plugin.prodrift' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.158] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.process-discoverer' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.158] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.plugin.process-discoverer' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.159] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.stagemining-logic' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.160] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.stagemining-portal-plugin' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.161] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.plugin.stagemining' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.162] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.predictive-monitor-logic' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.163] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.predictive-monitor-portal-plugin' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.164] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.plugin.predictive-monitor' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.165] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.predictor-training-portal-plugin' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.166] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.plugin.predictor-training' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.168] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.perfmining-logic' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.169] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.perfmining-portal-plugin' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.170] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.plugin.perfmining' version '1.0.0'. 
apromore_1            | [2019-07-23 14:00:39.171] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.similaritysearch-osgi' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.172] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.similaritysearch-logic' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.173] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.similaritysearch-portal' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.174] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.plugin.similaritysearch' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.176] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.merge-logic' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.177] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.merge-portal' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.179] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.plugin.merge' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.180] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.metrics-logic' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.183] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.metrics-portal-plugin' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.184] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.metrics-editor-plugin' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.184] fs-watcher                   <DE0003E> Install failed for bundle 'org.apromore.plugin.metrics-editor-plugin2' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.185] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.plugin.metrics' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.186] fs-watcher                   <DE0003E> Install failed for plan 'org.apromore.root' version '1.1.0'. 
apromore_1            | [2019-07-23 14:00:39.190] fs-watcher                   <DE0500E> Unable to install application from URI 'file:/opt/apromore/virgo-tomcat-server-3.6.4.RELEASE/pickup/apromore-root.plan'. Cannot satisfy constraints for bundle 'org.apromore.plugin.compareBP-portal-plugin' version '1.1.0'. Cannot resolve: org.apromore.plugin.compareBP-portal-plugin
apromore_1            |     Resolver report:
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.compareBP-portal-plugin_1.1.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.apache.xml.resolver; version="0.0.0">. Caused by missing constraint in bundle <com.sun.xml.bind.extra_2.2.7>
apromore_1            |              constraint: <Import-Package: org.apache.xml.resolver; version="0.0.0">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: com.sun.xml.bind.serializer; version="[2.2.0,2.2.0]">. Caused by missing constraint in bundle <com.springsource.com.sun.tools.xjc_2.2.0>
apromore_1            |              constraint: <Import-Package: com.sun.xml.bind.serializer; version="[2.2.0,2.2.0]">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.log-animation-portal-plugin2_1.0.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.compareBP-portal-plugin2_1.1.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.model; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.log-animation-portal-plugin_1.0.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.model; version="[2.16.0,3.0.0)">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.extension.std; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.process-discoverer_1.0.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.extension.std; version="[2.16.0,3.0.0)">
apromore_1            | . org.eclipse.virgo.kernel.osgi.framework.UnableToSatisfyBundleDependenciesException: Unable to satisfy dependencies of bundle 'org.apromore.plugin.compareBP-portal-plugin' at version '1.1.0': Cannot resolve: org.apromore.plugin.compareBP-portal-plugin
apromore_1            |     Resolver report:
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.compareBP-portal-plugin_1.1.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.apache.xml.resolver; version="0.0.0">. Caused by missing constraint in bundle <com.sun.xml.bind.extra_2.2.7>
apromore_1            |              constraint: <Import-Package: org.apache.xml.resolver; version="0.0.0">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: com.sun.xml.bind.serializer; version="[2.2.0,2.2.0]">. Caused by missing constraint in bundle <com.springsource.com.sun.tools.xjc_2.2.0>
apromore_1            |              constraint: <Import-Package: com.sun.xml.bind.serializer; version="[2.2.0,2.2.0]">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.log-animation-portal-plugin2_1.0.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.compareBP-portal-plugin2_1.1.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.model; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.log-animation-portal-plugin_1.0.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.model; version="[2.16.0,3.0.0)">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.extension.std; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.process-discoverer_1.0.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.extension.std; version="[2.16.0,3.0.0)">
apromore_1            | 
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.stage.resolve.internal.QuasiResolveStage.process(QuasiResolveStage.java:46)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.internal.StandardPipeline.doProcessGraph(StandardPipeline.java:62)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.internal.CompensatingPipeline.doProcessGraph(CompensatingPipeline.java:73)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.stage.AbstractPipelineStage.process(AbstractPipelineStage.java:41)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.internal.StandardPipeline.doProcessGraph(StandardPipeline.java:62)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.stage.AbstractPipelineStage.process(AbstractPipelineStage.java:41)
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.driveInstallPipeline(PipelinedApplicationDeployer.java:359)
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.doInstall(PipelinedApplicationDeployer.java:185)
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.install(PipelinedApplicationDeployer.java:140)
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.deploy(PipelinedApplicationDeployer.java:253)
apromore_1            | 	at org.eclipse.virgo.nano.deployer.hot.HotDeploymentFileSystemListener.deploy(HotDeployerFileSystemListener.java:225)
apromore_1            | 	at org.eclipse.virgo.nano.deployer.hot.HotDeploymentFileSystemListener.deployIfNotDeployed(HotDeployerFileSystemListener.java:237)
apromore_1            | 	at org.eclipse.virgo.nano.deployer.hot.HotDeploymentFileSystemListener.onChange(HotDeployerFileSystemListener.java:88)
apromore_1            | 	at org.eclipse.virgo.util.io.FileSystemChecker.notifyListeners(FileSystemChecker.java:380)
apromore_1            | 	at org.eclipse.virgo.util.io.FileSystemChecker.check(FileSystemChecker.java:289)
apromore_1            | 	at org.eclipse.virgo.nano.deployer.hot.WatchTask.run(WatchTask.java:49)
apromore_1            | 	at java.lang.Thread.run(Thread.java:748)
apromore_1            | 
apromore_1            | [2019-07-23 14:00:39.198] fs-watcher                   <HD0002E> Hot deploy failed for file 'apromore-root.plan'. org.eclipse.virgo.nano.deployer.api.core.DeploymentException: Dependency satisfaction failed
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.driveInstallPipeline(PipelinedApplicationDeployer.java:362)
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.doInstall(PipelinedApplicationDeployer.java:185)
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.install(PipelinedApplicationDeployer.java:140)
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.deploy(PipelinedApplicationDeployer.java:253)
apromore_1            | 	at org.eclipse.virgo.nano.deployer.hot.HotDeploymentFileSystemListener.deploy(HotDeployerFileSystemListener.java:225)
apromore_1            | 	at org.eclipse.virgo.nano.deployer.hot.HotDeploymentFileSystemListener.deployIfNotDeployed(HotDeployerFileSystemListener.java:237)
apromore_1            | 	at org.eclipse.virgo.nano.deployer.hot.HotDeploymentFileSystemListener.onChange(HotDeployerFileSystemListener.java:88)
apromore_1            | 	at org.eclipse.virgo.util.io.FileSystemChecker.notifyListeners(FileSystemChecker.java:380)
apromore_1            | 	at org.eclipse.virgo.util.io.FileSystemChecker.check(FileSystemChecker.java:289)
apromore_1            | 	at org.eclipse.virgo.nano.deployer.hot.WatchTask.run(WatchTask.java:49)
apromore_1            | 	at java.lang.Thread.run(Thread.java:748)
apromore_1            | Caused by: org.eclipse.virgo.kernel.osgi.framework.UnableToSatisfyBundleDependenciesException: Unable to satisfy dependencies of bundle 'org.apromore.plugin.compareBP-portal-plugin' at version '1.1.0': Cannot resolve: org.apromore.plugin.compareBP-portal-plugin
apromore_1            |     Resolver report:
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.compareBP-portal-plugin_1.1.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.apache.xml.resolver; version="0.0.0">. Caused by missing constraint in bundle <com.sun.xml.bind.extra_2.2.7>
apromore_1            |              constraint: <Import-Package: org.apache.xml.resolver; version="0.0.0">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: com.sun.xml.bind.serializer; version="[2.2.0,2.2.0]">. Caused by missing constraint in bundle <com.springsource.com.sun.tools.xjc_2.2.0>
apromore_1            |              constraint: <Import-Package: com.sun.xml.bind.serializer; version="[2.2.0,2.2.0]">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.log-animation-portal-plugin2_1.0.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.compareBP-portal-plugin2_1.1.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.in; version="[2.16.0,3.0.0)">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.model; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.log-animation-portal-plugin_1.0.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.model; version="[2.16.0,3.0.0)">
apromore_1            |         An Import-Package could not be resolved. Resolver error data <Import-Package: org.deckfour.xes.extension.std; version="[2.16.0,3.0.0)">. Caused by missing constraint in bundle <org.apromore.plugin.process-discoverer_1.0.0>
apromore_1            |              constraint: <Import-Package: org.deckfour.xes.extension.std; version="[2.16.0,3.0.0)">
apromore_1            | 
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.stage.resolve.internal.QuasiResolveStage.process(QuasiResolveStage.java:46)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.internal.StandardPipeline.doProcessGraph(StandardPipeline.java:62)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.internal.CompensatingPipeline.doProcessGraph(CompensatingPipeline.java:73)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.stage.AbstractPipelineStage.process(AbstractPipelineStage.java:41)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.internal.StandardPipeline.doProcessGraph(StandardPipeline.java:62)
apromore_1            | 	at org.eclipse.virgo.kernel.install.pipeline.stage.AbstractPipelineStage.process(AbstractPipelineStage.java:41)
apromore_1            | 	at org.eclipse.virgo.kernel.deployer.core.internal.PipelinedApplicationDeployer.driveInstallPipeline(PipelinedApplicationDeployer.java:359)
